{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "2.0.0+cu117\n"
     ]
    },
    {
     "data": {
      "text/plain": "'%.4f'"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import importlib\n",
    "import life.lib\n",
    "import life.lib as lib\n",
    "import typing\n",
    "importlib.reload(lib)\n",
    "LOG = lib.simple_log.LOG\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib\n",
    "plt.ion()\n",
    "lib.utils.set_seed()\n",
    "print(torch.__version__)\n",
    "np.set_printoptions(precision=3)\n",
    "%precision 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def get_mnist2():\n",
    "    x, y = lib.datasets.get_mnist_train()\n",
    "    train_y = y % 2\n",
    "    train_x = torch.reshape(x, (len(x), -1))\n",
    "    x, y = lib.datasets.get_mnist_test()\n",
    "    test_y = y % 2\n",
    "    test_x = torch.reshape(x, (len(x), -1))\n",
    "    return train_x, train_y\n",
    "\n",
    "dataset_func = lib.datasets.get_odd\n",
    "\n",
    "if \"train_x\" not in globals():\n",
    "    train_x, train_y = dataset_func()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def create_optimizer(net: nn.Module):\n",
    "    if net.__class__.__name__ == \"LiveNet\":\n",
    "        print(\"LiveNet\")\n",
    "        net: lib.livenet.LiveNet\n",
    "        optimizer = lib.livenet.LiveNetOptimizer(net, decay=0.0)\n",
    "        # optimizer = torch.optim.Adam(net.parameters())\n",
    "    else:\n",
    "        print(\"Torch\")\n",
    "        optimizer = lib.optimizer.optimizer_with_lr_property(torch.optim.Adam, net.parameters(), betas=(0.0, 0.95))\n",
    "    return optimizer\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch\n"
     ]
    }
   ],
   "source": [
    "lib.utils.set_seed()\n",
    "network = lib.nets.ODD()\n",
    "batch_iterator = lib.gen_utils.batch_iterator(train_x, train_y, batch_size=len(train_x))\n",
    "criterion = lib.nets.criterion_1\n",
    "optimizer = create_optimizer(network)\n",
    "optimizer.learning_rate = 0.01\n",
    "trainer = lib.trainer.Trainer(network, batch_iterator, criterion, optimizer, epoch_size=1, adaptive_lr=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iˈ0.000 0.310 lib/trainer.py:89\n",
      "Iˈ0.001 0.305 lib/trainer.py:89\n",
      "Iˈ0.002 0.301 lib/trainer.py:89\n",
      "Iˈ0.003 0.297 lib/trainer.py:89\n",
      "Iˈ0.004 0.293 lib/trainer.py:89\n",
      "Iˈ0.004 0.289 lib/trainer.py:89\n",
      "Iˈ0.005 0.285 lib/trainer.py:89\n",
      "Iˈ0.006 0.281 lib/trainer.py:89\n",
      "Iˈ0.007 0.277 lib/trainer.py:89\n",
      "Iˈ0.007 0.273 lib/trainer.py:89\n",
      "Iˈ0.008 0.269 lib/trainer.py:89\n",
      "Iˈ0.009 0.266 lib/trainer.py:89\n",
      "Iˈ0.009 0.262 lib/trainer.py:89\n",
      "Iˈ0.010 0.258 lib/trainer.py:89\n",
      "Iˈ0.010 0.255 lib/trainer.py:89\n",
      "Iˈ0.011 0.251 lib/trainer.py:89\n",
      "Iˈ0.012 0.248 lib/trainer.py:89\n",
      "Iˈ0.012 0.244 lib/trainer.py:89\n",
      "Iˈ0.013 0.241 lib/trainer.py:89\n",
      "Iˈ0.014 0.237 lib/trainer.py:89\n",
      "Iˈ0.015 0.234 lib/trainer.py:89\n",
      "Iˈ0.015 0.231 lib/trainer.py:89\n",
      "Iˈ0.016 0.227 lib/trainer.py:89\n",
      "Iˈ0.017 0.224 lib/trainer.py:89\n",
      "Iˈ0.018 0.221 lib/trainer.py:89\n",
      "Iˈ0.018 0.218 lib/trainer.py:89\n",
      "Iˈ0.019 0.215 lib/trainer.py:89\n",
      "Iˈ0.020 0.212 lib/trainer.py:89\n",
      "Iˈ0.021 0.209 lib/trainer.py:89\n",
      "Iˈ0.021 0.206 lib/trainer.py:89\n",
      "Iˈ0.022 0.203 lib/trainer.py:89\n",
      "Iˈ0.022 0.200 lib/trainer.py:89\n",
      "Iˈ0.023 0.197 lib/trainer.py:89\n",
      "Iˈ0.024 0.194 lib/trainer.py:89\n",
      "Iˈ0.024 0.192 lib/trainer.py:89\n",
      "Iˈ0.025 0.189 lib/trainer.py:89\n",
      "Iˈ0.025 0.186 lib/trainer.py:89\n",
      "Iˈ0.026 0.184 lib/trainer.py:89\n",
      "Iˈ0.027 0.181 lib/trainer.py:89\n",
      "Iˈ0.027 0.178 lib/trainer.py:89\n",
      "Iˈ0.028 0.176 lib/trainer.py:89\n",
      "Iˈ0.029 0.173 lib/trainer.py:89\n",
      "Iˈ0.029 0.171 lib/trainer.py:89\n",
      "Iˈ0.030 0.168 lib/trainer.py:89\n",
      "Iˈ0.030 0.166 lib/trainer.py:89\n",
      "Iˈ0.031 0.164 lib/trainer.py:89\n",
      "Iˈ0.031 0.161 lib/trainer.py:89\n",
      "Iˈ0.032 0.159 lib/trainer.py:89\n",
      "Iˈ0.032 0.157 lib/trainer.py:89\n",
      "Iˈ0.033 0.154 lib/trainer.py:89\n",
      "Iˈ0.033 0.152 lib/trainer.py:89\n",
      "Iˈ0.034 0.150 lib/trainer.py:89\n",
      "Iˈ0.034 0.148 lib/trainer.py:89\n",
      "Iˈ0.035 0.146 lib/trainer.py:89\n",
      "Iˈ0.035 0.144 lib/trainer.py:89\n",
      "Iˈ0.036 0.142 lib/trainer.py:89\n",
      "Iˈ0.036 0.140 lib/trainer.py:89\n",
      "Iˈ0.036 0.138 lib/trainer.py:89\n",
      "Iˈ0.037 0.136 lib/trainer.py:89\n",
      "Iˈ0.037 0.134 lib/trainer.py:89\n",
      "Iˈ0.038 0.132 lib/trainer.py:89\n",
      "Iˈ0.038 0.130 lib/trainer.py:89\n",
      "Iˈ0.039 0.128 lib/trainer.py:89\n",
      "Iˈ0.039 0.126 lib/trainer.py:89\n",
      "Iˈ0.040 0.125 lib/trainer.py:89\n",
      "Iˈ0.040 0.123 lib/trainer.py:89\n",
      "Iˈ0.041 0.121 lib/trainer.py:89\n",
      "Iˈ0.041 0.120 lib/trainer.py:89\n",
      "Iˈ0.041 0.118 lib/trainer.py:89\n",
      "Iˈ0.042 0.116 lib/trainer.py:89\n",
      "Iˈ0.042 0.115 lib/trainer.py:89\n",
      "Iˈ0.043 0.113 lib/trainer.py:89\n",
      "Iˈ0.043 0.111 lib/trainer.py:89\n",
      "Iˈ0.044 0.110 lib/trainer.py:89\n",
      "Iˈ0.044 0.108 lib/trainer.py:89\n",
      "Iˈ0.045 0.107 lib/trainer.py:89\n",
      "Iˈ0.045 0.105 lib/trainer.py:89\n",
      "Iˈ0.046 0.104 lib/trainer.py:89\n",
      "Iˈ0.047 0.103 lib/trainer.py:89\n",
      "Iˈ0.047 0.101 lib/trainer.py:89\n",
      "Iˈ0.048 0.100 lib/trainer.py:89\n",
      "Iˈ0.048 0.098 lib/trainer.py:89\n",
      "Iˈ0.048 0.097 lib/trainer.py:89\n",
      "Iˈ0.049 0.096 lib/trainer.py:89\n",
      "Iˈ0.049 0.094 lib/trainer.py:89\n",
      "Iˈ0.050 0.093 lib/trainer.py:89\n",
      "Iˈ0.050 0.092 lib/trainer.py:89\n",
      "Iˈ0.051 0.091 lib/trainer.py:89\n",
      "Iˈ0.051 0.089 lib/trainer.py:89\n",
      "Iˈ0.052 0.088 lib/trainer.py:89\n",
      "Iˈ0.053 0.087 lib/trainer.py:89\n",
      "Iˈ0.053 0.086 lib/trainer.py:89\n",
      "Iˈ0.053 0.085 lib/trainer.py:89\n",
      "Iˈ0.054 0.084 lib/trainer.py:89\n",
      "Iˈ0.054 0.082 lib/trainer.py:89\n",
      "Iˈ0.055 0.081 lib/trainer.py:89\n",
      "Iˈ0.055 0.080 lib/trainer.py:89\n",
      "Iˈ0.056 0.079 lib/trainer.py:89\n",
      "Iˈ0.056 0.078 lib/trainer.py:89\n",
      "Iˈ0.057 0.077 lib/trainer.py:89\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.step(100)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "0.3333"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = network(train_x)\n",
    "pred_bin = np.argmax(pred.detach().numpy(), axis=1, keepdims=True)\n",
    "diff = train_y - pred_bin\n",
    "len(diff[diff != 0]) / len(diff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(lib)\n",
    "%matplotlib\n",
    "plt.ion()\n",
    "\n",
    "def param_picker0(param):\n",
    "    val0 = param[\"params\"][\"linear1.weight\"][0][0].item()\n",
    "    val1 = param[\"params\"][\"linear1.weight\"][1][0].item()\n",
    "    return val1 + val0\n",
    "\n",
    "def param_picker1(param):\n",
    "    val0 = param[\"params\"][\"linear1.weight\"][0][1].item()\n",
    "    return val0\n",
    "    return param[\"grads\"][\"linear1.weight\"][0][0].item() / 1000\n",
    "    # return np.max(np.abs(param[0].numpy()))\n",
    "\n",
    "def get_param_values(history, picker):\n",
    "    values = []\n",
    "    for entry in history:\n",
    "        values.append(picker(entry))\n",
    "    return values\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "# values = get_param_values(trainer.history, param_picker0)\n",
    "# plt.plot(values)\n",
    "# values = get_param_values(trainer.history, param_picker1)\n",
    "# plt.plot(values)\n",
    "plt.grid()\n",
    "\n",
    "accum = lib.stat_utils.AccumStat()\n",
    "accum.add_value(trainer.network.parameters())\n",
    "accum.plot()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def form_balanced(x, y, n):\n",
    "    assert n % 2 == 0\n",
    "    n //= 2\n",
    "    y = y.numpy()\n",
    "    x = x.numpy()\n",
    "    inds = np.argsort(y.squeeze(1), axis=0)\n",
    "    y = y[inds]\n",
    "    x = x[inds]\n",
    "    i = 0\n",
    "    batches_x = []\n",
    "    batches_y = []\n",
    "    while True:\n",
    "        a = y[i:i + n]\n",
    "        b = y[len(y) - i - n: len(y) - i]\n",
    "        if not (a==0).all() or not (b==1).all():\n",
    "            break\n",
    "        batches_x += [x[i:i+n], x[len(y) - i - n: len(y) - i]]\n",
    "        batches_y += [a, b]\n",
    "        i += n\n",
    "\n",
    "    x = np.vstack(batches_x)\n",
    "    y = np.vstack(batches_y)\n",
    "    return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "train_x, train_y = form_balanced(train_x, train_y, 1000)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
