{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "2.0.0+cu117\n"
     ]
    },
    {
     "data": {
      "text/plain": "'%.4f'"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import importlib\n",
    "import life.lib\n",
    "import life.lib as lib\n",
    "importlib.reload(lib)\n",
    "LOG = lib.simple_log.LOG\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib\n",
    "plt.ion()\n",
    "lib.utils.set_seed()\n",
    "print(torch.__version__)\n",
    "np.set_printoptions(precision=3)\n",
    "%precision 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "if \"train_x\" not in globals():\n",
    "    x, y = lib.datasets.get_mnist_train()\n",
    "    train_y = y % 2\n",
    "    train_x = torch.reshape(x, (len(x), -1))\n",
    "    x, y = lib.datasets.get_mnist_test()\n",
    "    test_y = y % 2\n",
    "    test_x = torch.reshape(x, (len(x), -1))\n",
    "\n",
    "b = train_x[:, 0].numpy()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch\n"
     ]
    }
   ],
   "source": [
    "lib.utils.set_seed()\n",
    "# network = lib.nets.PYRAMID()\n",
    "#network = lib.nets.create_livenet_odd_2()\n",
    "# train_x, train_y = lib.datasets.get_odd()\n",
    "# network = lib.livenet.LiveNet(train_x.shape[1], None, torch.max(train_y) + 1)\n",
    "network = lib.nets.PERCEPTRON(train_x.shape[1], torch.max(train_y) + 1, l1=0.1)\n",
    "criterion = lib.nets.criterion_n\n",
    "\n",
    "def create_optimizer(net: nn.Module):\n",
    "    if net.__class__.__name__ == \"LiveNet\":\n",
    "        print(\"LiveNet\")\n",
    "        net: lib.livenet.LiveNet\n",
    "        optimizer = lib.livenet.LiveNetOptimizer(net, decay=0.0)\n",
    "        # optimizer = torch.optim.Adam(net.parameters())\n",
    "    else:\n",
    "        print(\"Torch\")\n",
    "        optimizer = torch.optim.Adam(net.parameters(), betas=(0.0, 0.95))\n",
    "        # optimizer = torch.optim.Adam(net.parameters())\n",
    "    return optimizer\n",
    "\n",
    "optimizer = create_optimizer(network)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight [[-0.     0.019 -0.029 ...  0.022  0.004  0.002]\n",
      " [-0.02  -0.015 -0.01  ... -0.02  -0.006 -0.03 ]]\n",
      "linear1.bias [-0.02   0.015]\n",
      "tensor(1.0976, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[-0.019,  0.095],\n       [-0.075,  0.143],\n       [-0.086,  1.06 ],\n       ...,\n       [ 0.613,  0.59 ],\n       [ 0.102,  0.75 ],\n       [ 0.193,  0.402]], dtype=float32)"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [p for p in network.named_parameters()]\n",
    "logits = network.forward(train_x)\n",
    "for name, p in params:\n",
    "    print(f\"{name} {p.detach().numpy()}\")\n",
    "pred = network.forward(train_x)\n",
    "loss = criterion(pred, train_y)\n",
    "print(loss)\n",
    "pred.detach().numpy()\n",
    "# torch.onnx.export(network, train_x, \"/home/spometun/model.onnx\", verbose=False)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "params_history = []\n",
    "\n",
    "def get_gradients_dict(network: torch.nn.Module):\n",
    "    res = {}\n",
    "    for name, param in network.named_parameters():\n",
    "        with torch.no_grad():\n",
    "            res[name] = param.grad\n",
    "    return res\n",
    "\n",
    "g = get_gradients_dict(network)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iˈ0.000 0.886 = 0.701+0.186 \n",
      "Iˈ0.065 0.886 = 0.700+0.186 \n",
      "Iˈ0.123 0.886 = 0.699+0.187 \n",
      "Iˈ0.180 0.886 = 0.699+0.187 \n",
      "Iˈ0.236 0.886 = 0.699+0.187 \n",
      "Iˈ0.296 0.886 = 0.697+0.189 \n",
      "Iˈ0.352 0.886 = 0.697+0.188 \n",
      "Iˈ0.415 0.886 = 0.696+0.190 \n"
     ]
    }
   ],
   "source": [
    "optimizer.param_groups[0][\"lr\"] = 0.0001\n",
    "network.alpha_l1 = 0.1\n",
    "batch_size = 1000\n",
    "\n",
    "n_epochs = 8\n",
    "for i in range(n_epochs):\n",
    "    e_counter = 0\n",
    "    for start, end in lib.gen_utils.index_batcher(batch_size, len(train_x)):\n",
    "        y = train_y[start:end]\n",
    "        pred = network.forward(x)\n",
    "        loss = criterion(pred, y)\n",
    "        reg_loss = network.internal_loss()\n",
    "        all_loss = loss + reg_loss\n",
    "        optimizer.zero_grad()\n",
    "        all_loss.backward()\n",
    "\n",
    "        params = lib.utils.get_parameters_dict(network)\n",
    "        grads = lib.utils.get_gradients_dict(network)\n",
    "        params_history.append({\"params\": params, \"grads\": grads})\n",
    "\n",
    "        optimizer.step()\n",
    "        if e_counter == 0:\n",
    "            LOG(f\"{all_loss.detach().numpy():.3f} = {loss.detach().numpy():.3f}+{reg_loss.detach().numpy():.3f}\")\n",
    "        e_counter += 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "\n",
    "params_orig = [p.detach().clone().numpy() for p in network.parameters()]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "# params = copy.deepcopy(params_orig)\n",
    "#lib.utils.add_noise_to_params(params, 1, .0)\n",
    "# lib.utils.set_parameters(network, params)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "0.1886"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = network(train_x)\n",
    "pred_bin = np.argmax(pred.detach().numpy(), axis=1, keepdims=True)\n",
    "diff = train_y - pred_bin\n",
    "len(diff[diff != 0]) / len(diff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(lib)\n",
    "%matplotlib\n",
    "plt.ion()\n",
    "\n",
    "def param_picker0(param):\n",
    "    val0 = param[\"params\"][\"linear1.weight\"][0][0].item()\n",
    "    val1 = param[\"params\"][\"linear1.weight\"][1][0].item()\n",
    "    return val1 + val0\n",
    "\n",
    "def param_picker1(param):\n",
    "    val0 = param[\"params\"][\"linear1.weight\"][0][1].item()\n",
    "    return val0\n",
    "    return param[\"grads\"][\"linear1.weight\"][0][0].item() / 1000\n",
    "    # return np.max(np.abs(param[0].numpy()))\n",
    "\n",
    "def get_param_values(history, picker):\n",
    "    values = []\n",
    "    for entry in history:\n",
    "        values.append(picker(entry))\n",
    "    return values\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "values = get_param_values(params_history, param_picker0)\n",
    "# plt.plot(values)\n",
    "values = get_param_values(params_history, param_picker1)\n",
    "plt.plot(values)\n",
    "plt.grid()\n",
    "\n",
    "accum = lib.stat_utils.AccumStat()\n",
    "accum.add_value(network.parameters())\n",
    "#accum.add_value(params_history[-1])\n",
    "accum.plot()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def form_balanced(x, y, n):\n",
    "    assert n % 2 == 0\n",
    "    n //= 2\n",
    "    y = y.numpy()\n",
    "    x = x.numpy()\n",
    "    inds = np.argsort(y.squeeze(1), axis=0)\n",
    "    y = y[inds]\n",
    "    x = x[inds]\n",
    "    i = 0\n",
    "    batches_x = []\n",
    "    batches_y = []\n",
    "    while True:\n",
    "        a = y[i:i + n]\n",
    "        b = y[len(y) - i - n: len(y) - i]\n",
    "        if not (a==0).all() or not (b==1).all():\n",
    "            break\n",
    "        batches_x += [x[i:i+n], x[len(y) - i - n: len(y) - i]]\n",
    "        batches_y += [a, b]\n",
    "        i += n\n",
    "\n",
    "    x = np.vstack(batches_x)\n",
    "    y = np.vstack(batches_y)\n",
    "    return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "train_x, train_y = form_balanced(train_x, train_y, 1000)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# list(network.parameters())[0].data = torch.Tensor([[10.], [-10]])\n",
    "# list(network.parameters())[1].data = torch.Tensor([-5., 15])\n",
    "np.set_printoptions(precision=2)\n",
    "params = list(network.parameters())\n",
    "par = []\n",
    "for p in params:\n",
    "    par.append(p.detach())\n",
    "    print (par[-1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "o1 = train_x @ par[1].T + par[2]\n",
    "o1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a1 = torch.sigmoid(o1)\n",
    "a1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "o2 = a1[:, 0] + a1[:, 1] - 1\n",
    "mseloss(o2, train_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "o2 @ par[2].T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network.forward(train_x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "1345639 * 5145"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "class A:\n",
    "    def __init__(self):\n",
    "        self.v = 1\n",
    "    def __del__(self):\n",
    "        print(f\"del {self.v}\")\n",
    "\n",
    "a = A()\n",
    "b = A()\n",
    "b.v = 2\n",
    "l = [b]\n",
    "print(\"start\")\n",
    "del a\n",
    "print(\"after del\")\n",
    "l[0].v\n",
    "a.v\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
