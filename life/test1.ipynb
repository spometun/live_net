{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "2.0.0+cu117\n"
     ]
    },
    {
     "data": {
      "text/plain": "'%.4f'"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import importlib\n",
    "import life.lib\n",
    "import life.lib as lib\n",
    "import typing\n",
    "importlib.reload(lib)\n",
    "LOG = lib.simple_log.LOG\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib\n",
    "plt.ion()\n",
    "lib.utils.set_seed()\n",
    "print(torch.__version__)\n",
    "np.set_printoptions(precision=3)\n",
    "%precision 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "if \"train_x\" not in globals():\n",
    "    x, y = lib.datasets.get_mnist_train()\n",
    "    train_y = y % 2\n",
    "    train_x = torch.reshape(x, (len(x), -1))\n",
    "    x, y = lib.datasets.get_mnist_test()\n",
    "    test_y = y % 2\n",
    "    test_x = torch.reshape(x, (len(x), -1))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch\n"
     ]
    }
   ],
   "source": [
    "lib.utils.set_seed()\n",
    "# network = lib.nets.PYRAMID()\n",
    "#network = lib.nets.create_livenet_odd_2()\n",
    "# train_x, train_y = lib.datasets.get_odd()\n",
    "# network = lib.livenet.LiveNet(train_x.shape[1], None, torch.max(train_y) + 1)\n",
    "network = lib.nets.PERCEPTRON(train_x.shape[1], torch.max(train_y) + 1, l1=0.01)\n",
    "criterion = lib.nets.criterion_n\n",
    "\n",
    "def create_optimizer(net: nn.Module):\n",
    "    if net.__class__.__name__ == \"LiveNet\":\n",
    "        print(\"LiveNet\")\n",
    "        net: lib.livenet.LiveNet\n",
    "        optimizer = lib.livenet.LiveNetOptimizer(net, decay=0.0)\n",
    "        # optimizer = torch.optim.Adam(net.parameters())\n",
    "    else:\n",
    "        print(\"Torch\")\n",
    "        optimizer = torch.optim.Adam(net.parameters(), betas=(0.0, 0.95))\n",
    "        # optimizer = torch.optim.Adam(net.parameters())\n",
    "    return optimizer\n",
    "\n",
    "optimizer = create_optimizer(network)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight [[-0.     0.019 -0.029 ...  0.022  0.004  0.002]\n",
      " [-0.02  -0.015 -0.01  ... -0.02  -0.006 -0.03 ]]\n",
      "linear1.bias [-0.02   0.015]\n",
      "tensor(1.0939, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 0.273,  0.635],\n       [-0.329,  0.542],\n       [ 0.153, -0.004],\n       ...,\n       [ 0.304,  0.578],\n       [ 0.077,  0.333],\n       [-0.019,  0.095]], dtype=float32)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [p for p in network.named_parameters()]\n",
    "logits = network.forward(train_x)\n",
    "for name, p in params:\n",
    "    print(f\"{name} {p.detach().numpy()}\")\n",
    "pred = network.forward(train_x)\n",
    "loss = criterion(pred, train_y)\n",
    "print(loss)\n",
    "pred.detach().numpy()\n",
    "# torch.onnx.export(network, train_x, \"/home/spometun/model.onnx\", verbose=False)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, network: torch.nn.Module, batch_iterator: typing.Iterator,\n",
    "                  criterion: typing.Callable, optimizer, epoch_size=1):\n",
    "        self.network = network\n",
    "        self.batch_iterator = batch_iterator\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.epoch_size = epoch_size\n",
    "        self.history = []\n",
    "        self.counter = 0\n",
    "\n",
    "    def step(self, n_steps=1):\n",
    "        for _ in range(n_steps):\n",
    "            self._step()\n",
    "\n",
    "    def _step(self):\n",
    "        data, labels = next(self.batch_iterator)\n",
    "        pred = self.network.forward(data)\n",
    "        loss = self.criterion(pred, labels)\n",
    "        reg_loss = self.network.internal_loss()\n",
    "        all_loss = loss + reg_loss\n",
    "        self.optimizer.zero_grad()\n",
    "        all_loss.backward()\n",
    "        if self.counter % self.epoch_size == 0:\n",
    "            params = lib.utils.get_parameters_dict(self.network)\n",
    "            grads = lib.utils.get_gradients_dict(self.network)\n",
    "            self.history.append({\"params\": params, \"grads\": grads})\n",
    "            LOG(f\"{all_loss.detach().numpy():.3f} = {loss.detach().numpy():.3f}+{reg_loss.detach().numpy():.3f}\")\n",
    "        self.optimizer.step()\n",
    "        self.counter += 1\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch\n"
     ]
    }
   ],
   "source": [
    "lib.utils.set_seed()\n",
    "network = lib.nets.PERCEPTRON(train_x.shape[1], torch.max(train_y) + 1, l1=0.01)\n",
    "batch_iterator = lib.gen_utils.batch_iterator(train_x, train_y, batch_size=1000)\n",
    "criterion = lib.nets.criterion_n\n",
    "optimizer = create_optimizer(network)\n",
    "trainer = Trainer(network, batch_iterator, criterion, optimizer, epoch_size=10)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iˈ0.000 0.689 = 0.479+0.209 \n",
      "Iˈ0.009 0.731 = 0.526+0.204 \n",
      "Iˈ0.049 0.688 = 0.493+0.195 \n",
      "Iˈ0.057 0.686 = 0.501+0.184 \n",
      "Iˈ0.065 0.663 = 0.482+0.181 \n",
      "Iˈ0.073 0.618 = 0.444+0.174 \n",
      "Iˈ0.080 0.684 = 0.513+0.171 \n",
      "Iˈ0.087 0.623 = 0.460+0.163 \n",
      "Iˈ0.129 0.657 = 0.497+0.160 \n",
      "Iˈ0.137 0.619 = 0.466+0.154 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.step(100)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0010"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_history = []\n",
    "optimizer.param_groups[0][\"lr\"]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iˈ0.000 1.391 = 1.105+0.286 \n",
      "Iˈ0.048 0.761 = 0.520+0.241 \n",
      "Iˈ0.093 0.704 = 0.508+0.196 \n",
      "Iˈ0.138 0.626 = 0.467+0.159 \n",
      "Iˈ0.179 0.603 = 0.467+0.135 \n",
      "Iˈ0.223 0.583 = 0.463+0.121 \n",
      "Iˈ0.275 0.569 = 0.454+0.115 \n",
      "Iˈ0.323 0.580 = 0.461+0.119 \n"
     ]
    }
   ],
   "source": [
    "optimizer.param_groups[0][\"lr\"] = 0.001\n",
    "network.alpha_l1 = 0.01\n",
    "batch_size = 1000\n",
    "\n",
    "n_epochs = 8\n",
    "for i in range(n_epochs):\n",
    "    e_counter = 0\n",
    "    for start, end in lib.gen_utils.index_batcher(batch_size, len(train_x)):\n",
    "        x = train_x[start:end]\n",
    "        y = train_y[start:end]\n",
    "        pred = network.forward(x)\n",
    "        loss = criterion(pred, y)\n",
    "        reg_loss = network.internal_loss()\n",
    "        all_loss = loss + reg_loss\n",
    "        optimizer.zero_grad()\n",
    "        all_loss.backward()\n",
    "\n",
    "        params = lib.utils.get_parameters_dict(network)\n",
    "        grads = lib.utils.get_gradients_dict(network)\n",
    "        params_history.append({\"params\": params, \"grads\": grads})\n",
    "\n",
    "        optimizer.step()\n",
    "        if e_counter == 0:\n",
    "            LOG(f\"{all_loss.detach().numpy():.3f} = {loss.detach().numpy():.3f}+{reg_loss.detach().numpy():.3f}\")\n",
    "        e_counter += 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "\n",
    "params_orig = [p.detach().clone().numpy() for p in network.parameters()]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "# params = copy.deepcopy(params_orig)\n",
    "#lib.utils.add_noise_to_params(params, 1, .0)\n",
    "# lib.utils.set_parameters(network, params)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "0.1886"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = network(train_x)\n",
    "pred_bin = np.argmax(pred.detach().numpy(), axis=1, keepdims=True)\n",
    "diff = train_y - pred_bin\n",
    "len(diff[diff != 0]) / len(diff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(lib)\n",
    "%matplotlib\n",
    "plt.ion()\n",
    "\n",
    "def param_picker0(param):\n",
    "    val0 = param[\"params\"][\"linear1.weight\"][0][0].item()\n",
    "    val1 = param[\"params\"][\"linear1.weight\"][1][0].item()\n",
    "    return val1 + val0\n",
    "\n",
    "def param_picker1(param):\n",
    "    val0 = param[\"params\"][\"linear1.weight\"][0][1].item()\n",
    "    return val0\n",
    "    return param[\"grads\"][\"linear1.weight\"][0][0].item() / 1000\n",
    "    # return np.max(np.abs(param[0].numpy()))\n",
    "\n",
    "def get_param_values(history, picker):\n",
    "    values = []\n",
    "    for entry in history:\n",
    "        values.append(picker(entry))\n",
    "    return values\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "values = get_param_values(params_history, param_picker0)\n",
    "# plt.plot(values)\n",
    "values = get_param_values(params_history, param_picker1)\n",
    "plt.plot(values)\n",
    "plt.grid()\n",
    "\n",
    "accum = lib.stat_utils.AccumStat()\n",
    "accum.add_value(network.parameters())\n",
    "#accum.add_value(params_history[-1])\n",
    "accum.plot()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def form_balanced(x, y, n):\n",
    "    assert n % 2 == 0\n",
    "    n //= 2\n",
    "    y = y.numpy()\n",
    "    x = x.numpy()\n",
    "    inds = np.argsort(y.squeeze(1), axis=0)\n",
    "    y = y[inds]\n",
    "    x = x[inds]\n",
    "    i = 0\n",
    "    batches_x = []\n",
    "    batches_y = []\n",
    "    while True:\n",
    "        a = y[i:i + n]\n",
    "        b = y[len(y) - i - n: len(y) - i]\n",
    "        if not (a==0).all() or not (b==1).all():\n",
    "            break\n",
    "        batches_x += [x[i:i+n], x[len(y) - i - n: len(y) - i]]\n",
    "        batches_y += [a, b]\n",
    "        i += n\n",
    "\n",
    "    x = np.vstack(batches_x)\n",
    "    y = np.vstack(batches_y)\n",
    "    return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "train_x, train_y = form_balanced(train_x, train_y, 1000)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# list(network.parameters())[0].data = torch.Tensor([[10.], [-10]])\n",
    "# list(network.parameters())[1].data = torch.Tensor([-5., 15])\n",
    "np.set_printoptions(precision=2)\n",
    "params = list(network.parameters())\n",
    "par = []\n",
    "for p in params:\n",
    "    par.append(p.detach())\n",
    "    print (par[-1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "o1 = train_x @ par[1].T + par[2]\n",
    "o1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a1 = torch.sigmoid(o1)\n",
    "a1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "o2 = a1[:, 0] + a1[:, 1] - 1\n",
    "mseloss(o2, train_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "o2 @ par[2].T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network.forward(train_x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "1345639 * 5145"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "class A:\n",
    "    def __init__(self):\n",
    "        self.v = 1\n",
    "    def __del__(self):\n",
    "        print(f\"del {self.v}\")\n",
    "\n",
    "a = A()\n",
    "b = A()\n",
    "b.v = 2\n",
    "l = [b]\n",
    "print(\"start\")\n",
    "del a\n",
    "print(\"after del\")\n",
    "l[0].v\n",
    "a.v\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
