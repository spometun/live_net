{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-25T01:32:30.305872Z",
     "start_time": "2025-05-25T01:32:27.519793Z"
    }
   },
   "source": [
    "# TODO:\n",
    "# reproducible results driven by seed\n",
    "# correlation of features output for two networks. Or even FC training from from to other with L1/L2 norm?\n",
    "# start develop liveconv\n",
    "# don't forger penalise for operation, not (just) weight. Add stats on operations\n",
    "# why features' weights small but not zero? should I try depth-separable conv?\n",
    "# manual livenet for cifar10, and then think on auto?\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torchsummary\n",
    "import numpy as np\n",
    "import gc\n",
    "from livenet.utils import set_seed\n",
    "import onnx\n",
    "import livenet\n",
    "device = \"cuda\"\n",
    "#device = \"cpu\"\n",
    "#torch.set_default_device(device)\n",
    "from ai_libs.simple_log import LOG\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T01:32:37.804899Z",
     "start_time": "2025-05-25T01:32:32.737912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 256\n",
    "from livenet.datasets import TransformDataset\n",
    "test_x, test_y = livenet.datasets.get_cifar10_test()\n",
    "test = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "test_aug = TransformDataset(test, livenet.datasets.cifar10_test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_aug, batch_size=batch_size, drop_last=True, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "train_x, train_y = livenet.datasets.get_cifar10_train()\n",
    "train = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "train_aug = TransformDataset(train, livenet.datasets.cifar10_train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_aug, batch_size=batch_size, drop_last=True, shuffle=True, num_workers=16, pin_memory=True, prefetch_factor=2)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "train_aug = TransformDataset(train, livenet.datasets.cifar10_train_transform)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img = train_aug[4][0].numpy()\n",
    "img = img.transpose(1, 2, 0)\n",
    "from matplotlib import pyplot as plt\n",
    "#img = livenet.datasets._elastic_transform(img, (-4, 0))\n",
    "img = (img * 128 + 127).astype(np.uint8)\n",
    "\n",
    "#plt.imsave(\"/home/spometun/img.png\", img)\n",
    "plt.imshow( img )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-25T01:32:41.004032Z"
    }
   },
   "source": [
    "# from cifar_arch import EffNet, ResNet9, ResNet9Small\n",
    "from livenet.v2.cifar_arch import ResNet9SmallSmart\n",
    "\n",
    "set_seed(2)\n",
    "\n",
    "# network = EffNet(device)\n",
    "# network = ResNet9Small(3, 10, device)\n",
    "network = ResNet9SmallSmart(3, 10, device)\n",
    "torchsummary.summary(network, (3, 32, 32), device=device)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dummy_input = torch.zeros(size=(1, 3, 32, 32), device=device)\n",
    "torch.onnx.export(network, dummy_input, \"/home/spometun/temp/resnet9small.onnx\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np.set_printoptions(precision=3, suppress=True)\n",
    "ax_in = (0, 2, 3)\n",
    "ax_out = (1, 2, 3)\n",
    "ax = ax_out\n",
    "vals = list(network.parameters())[32].data.cpu().numpy()\n",
    "vals_ref = list(network.parameters())[32].data\n",
    "out_max = np.max(vals, axis=ax)\n",
    "out_min = np.min(vals, axis=ax)\n",
    "sign = -out_min > out_max\n",
    "out = np.max(np.abs(vals), axis=ax)\n",
    "#out *= 1 - sign * 2\n",
    "LOG(f\"{np.min(vals):.2f} {np.max(vals):.2f}\")\n",
    "print(np.sum(np.abs(vals) < 0.01), np.sum(np.abs(vals) > 0.0))\n",
    "#vals_ref[np.abs(vals) < 0.05] = 0.0\n",
    "out"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-25T01:30:37.468826Z",
     "start_time": "2025-05-25T01:30:36.997648Z"
    }
   },
   "source": [
    "criterion = livenet.nets.criterion_classification_n\n",
    "optimizer = livenet.nets.create_optimizer(network)\n",
    "trainer = livenet.net_trainer.NetTrainer(network, train_loader, criterion, optimizer)\n",
    "trainer.adaptive_lr = True\n",
    "optimizer.learning_rate = 0.01\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T01:32:23.157258Z",
     "start_time": "2025-05-25T01:30:39.365713Z"
    }
   },
   "source": [
    "network.train()\n",
    "# trainer.optimizer.learning_rate = 0.01\n",
    "network._alpha = 10 * 1e-6\n",
    "trainer.step(2000)\n"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;66;03m# trainer.optimizer.learning_rate = 0.01\u001B[39;00m\n\u001B[32m      3\u001B[39m network._alpha = \u001B[32m10\u001B[39m * \u001B[32m1e-6\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m2000\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/home_project/livenet/net_trainer.py:63\u001B[39m, in \u001B[36mNetTrainer.step\u001B[39m\u001B[34m(self, n_steps)\u001B[39m\n\u001B[32m     61\u001B[39m     LOG(\u001B[33m\"\u001B[39m\u001B[33mstopped\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     62\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/home_project/livenet/net_trainer.py:86\u001B[39m, in \u001B[36mNetTrainer._step\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     83\u001B[39m all_loss = loss + loss_network\n\u001B[32m     85\u001B[39m \u001B[38;5;28mself\u001B[39m.optimizer.zero_grad()\n\u001B[32m---> \u001B[39m\u001B[32m86\u001B[39m \u001B[43mall_loss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     87\u001B[39m \u001B[38;5;28mself\u001B[39m.optimizer.step()\n\u001B[32m     89\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.adaptive_lr:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/_tensor.py:648\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    638\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    639\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    640\u001B[39m         Tensor.backward,\n\u001B[32m    641\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    646\u001B[39m         inputs=inputs,\n\u001B[32m    647\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m648\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    650\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    348\u001B[39m     retain_graph = create_graph\n\u001B[32m    350\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m353\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    822\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    823\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m824\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    825\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    826\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    827\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    828\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def _infer_epoch(network, loader):\n",
    "    preds = []\n",
    "    ys = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in iter(loader):\n",
    "            x = x.to(network.device)\n",
    "            pred = network(x)\n",
    "            pred = pred.cpu()\n",
    "            preds.append(pred)\n",
    "            ys.append(y.cpu())\n",
    "    pred = torch.concatenate(preds)\n",
    "    y = torch.concatenate(ys)\n",
    "    return pred, y\n",
    "\n",
    "\n",
    "network.train()\n",
    "#train_pred, train_labels = _infer_epoch(network, train_loader)\n",
    "test_pred, test_labels = _infer_epoch(network, test_loader)\n",
    "\n",
    "network.eval()\n",
    "test_pred, test_labels = _infer_epoch(network, test_loader)\n",
    "train_pred, train_labels = _infer_epoch(network, train_loader)\n",
    "\n",
    "def calc_accuracy(predictions, labels):\n",
    "    _, predicted = torch.max(predictions.data, 1)\n",
    "    labels = labels.numpy()\n",
    "    labels = np.squeeze(labels, 1)\n",
    "    predicted = predicted.numpy()\n",
    "    correct = np.sum(predicted == labels)\n",
    "    total = len(labels)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# test_y_tensor = torch.tensor(test_y, device=\"cpu\")\n",
    "# train_y_tensor = torch.tensor(train_y, device=\"cpu\")\n",
    "test_loss = trainer.criterion(test_pred, test_labels).item()\n",
    "train_loss = trainer.criterion(train_pred, train_labels).item()\n",
    "LOG(f\"loss: train: {train_loss:.3f} test: {test_loss:.3f}\")\n",
    "\n",
    "test_accuracy = calc_accuracy(test_pred, test_labels)\n",
    "train_accuracy = calc_accuracy(train_pred, train_labels)\n",
    "LOG(f\"accuracy, train: {100 * train_accuracy:.1f}% test: {100 * test_accuracy:.1f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "network.to(\"cpu\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param = list(network.named_parameters())\n",
    "param0 = list(network.parameters())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "w = param[12][1].detach().cpu().numpy()\n",
    "m = np.max(np.abs(w), axis=(1, 2, 3))\n",
    "f\"{int(100 * np.sum(m > 0.01) / len(m))}%\"\n",
    "np.sum(m > 0.01)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "outs = dict()\n",
    "for i in range(11):\n",
    "    ind = i * 4\n",
    "    if ind >= 36:\n",
    "        ind = 32 + (i - 8)\n",
    "    w = param[ind][1].detach().cpu().numpy()\n",
    "    w_name = param[ind][0]\n",
    "    m_out = np.max(np.abs(w), axis=(1, 2, 3))\n",
    "    outs[ind] = m_out > 0.01\n",
    "    m_in = np.max(np.abs(w), axis=(0, 2, 3))\n",
    "    n_out = np.sum(m_out > 0.01)\n",
    "    n_in = np.sum(m_in > 0.01)\n",
    "    s = f\"{w_name} {ind}, {w.shape} {int(100 * np.sum(m_out > 0.01) / len(m_out))}%, {n_in}->{n_out}\"\n",
    "    print(s)\n",
    "for ind in [12, 28]:\n",
    "    ind2 = 32 if ind == 12 else 33\n",
    "    n_inter = np.sum(outs[ind] * outs[ind2])\n",
    "    print(f\"{ind} inter={n_inter}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np.set_printoptions(1)\n",
    "w = param[12][1].detach().cpu().numpy()\n",
    "wa = np.abs(w)\n",
    "wa_max = np.max(wa, axis=(1, 2, 3))\n",
    "i = np.argsort(wa_max)[::-1]\n",
    "f = w[i[0]]\n",
    "fa = np.abs(f)\n",
    "fa_max = np.max(fa, axis=(1, 2))\n",
    "#print(f\"{wa_max[i]}\")\n",
    "# print(wa[i].shape)\n",
    "i1 = np.argsort(fa_max)[::-1]\n",
    "f1b = fa > 0.1\n",
    "np.sum(f1b)\n",
    "f[i1[2]]\n",
    "# fa[69]\n",
    "#f[i1]"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
