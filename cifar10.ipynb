{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-04T22:11:09.274292Z",
     "start_time": "2025-07-04T22:11:05.669730Z"
    }
   },
   "source": [
    "# TODO:\n",
    "# correlation of features output for two networks. Or even FC training from from to other with L1/L2 norm?\n",
    "# start develop liveconv\n",
    "# don't forger penalise for operation, not (just) weight. Add stats on operations\n",
    "# why features' weights small but not zero? should I try depth-separable conv?\n",
    "# manual livenet for cifar10, and then think on auto?\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torchsummary\n",
    "import numpy as np\n",
    "import gc\n",
    "from livenet.utils import set_seed\n",
    "import onnx\n",
    "import livenet\n",
    "from livenet.v2.context2 import Context2\n",
    "device = \"cuda\"\n",
    "#device = \"cpu\"\n",
    "#torch.set_default_device(device)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "from ai_libs.simple_log import LOG\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T22:11:19.093467Z",
     "start_time": "2025-07-04T22:11:12.318996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 256\n",
    "from livenet.datasets import TransformDataset\n",
    "test_x, test_y = livenet.datasets.get_cifar10_test()\n",
    "test = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "test_aug = TransformDataset(test, livenet.datasets.cifar10_test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_aug, batch_size=batch_size, drop_last=True, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "train_x, train_y = livenet.datasets.get_cifar10_train()\n",
    "train = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "train_aug = TransformDataset(train, livenet.datasets.cifar10_train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_aug, batch_size=batch_size, drop_last=True, shuffle=True, num_workers=16, pin_memory=True, prefetch_factor=2)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57.7%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T22:11:21.428057Z",
     "start_time": "2025-07-04T22:11:21.403891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "train_aug = TransformDataset(train, livenet.datasets.cifar10_train_transform)\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T22:11:27.484005Z",
     "start_time": "2025-07-04T22:11:27.391490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img = train_aug[4][0].numpy()\n",
    "img = img.transpose(1, 2, 0)\n",
    "from matplotlib import pyplot as plt\n",
    "#img = livenet.datasets._elastic_transform(img, (-4, 0))\n",
    "img = (img * 128 + 127).astype(np.uint8)\n",
    "\n",
    "#plt.imsave(\"/home/spometun/img.png\", img)\n",
    "plt.imshow( img )"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x70ecc851b260>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-04T22:11:35.172473Z",
     "start_time": "2025-07-04T22:11:33.737926Z"
    }
   },
   "source": [
    "# from cifar_arch import EffNet, ResNet9, ResNet9Small\n",
    "from livenet.v2.cifar_arch_smart import ResNet9SmallSmart\n",
    "\n",
    "set_seed(2)\n",
    "\n",
    "# network = EffNet(device)\n",
    "# network = ResNet9Small(3, 10, device)\n",
    "context = Context2(regularization_l1=0.001*1e-6)\n",
    "network = ResNet9SmallSmart(context, 3, 10, device)\n",
    "torchsummary.summary(network, (3, 32, 32), device=device)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       SmartConv2d-1           [-1, 16, 32, 32]             448\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "             ReLU6-3           [-1, 16, 32, 32]               0\n",
      "       SmartConv2d-4           [-1, 32, 32, 32]           4,640\n",
      "       BatchNorm2d-5           [-1, 32, 32, 32]              64\n",
      "             ReLU6-6           [-1, 32, 32, 32]               0\n",
      "         MaxPool2d-7           [-1, 32, 16, 16]               0\n",
      "       SmartConv2d-8           [-1, 32, 16, 16]           9,248\n",
      "       BatchNorm2d-9           [-1, 32, 16, 16]              64\n",
      "            ReLU6-10           [-1, 32, 16, 16]               0\n",
      "      SmartConv2d-11           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-12           [-1, 32, 16, 16]              64\n",
      "            ReLU6-13           [-1, 32, 16, 16]               0\n",
      "      SmartConv2d-14           [-1, 32, 16, 16]              64\n",
      "      SmartConv2d-15           [-1, 64, 16, 16]          18,496\n",
      "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
      "            ReLU6-17           [-1, 64, 16, 16]               0\n",
      "        MaxPool2d-18             [-1, 64, 8, 8]               0\n",
      "      SmartConv2d-19            [-1, 128, 8, 8]          73,856\n",
      "      BatchNorm2d-20            [-1, 128, 8, 8]             256\n",
      "            ReLU6-21            [-1, 128, 8, 8]               0\n",
      "        MaxPool2d-22            [-1, 128, 4, 4]               0\n",
      "      SmartConv2d-23            [-1, 128, 4, 4]         147,584\n",
      "      BatchNorm2d-24            [-1, 128, 4, 4]             256\n",
      "            ReLU6-25            [-1, 128, 4, 4]               0\n",
      "      SmartConv2d-26            [-1, 128, 4, 4]         147,584\n",
      "      BatchNorm2d-27            [-1, 128, 4, 4]             256\n",
      "            ReLU6-28            [-1, 128, 4, 4]               0\n",
      "        MaxPool2d-29            [-1, 128, 1, 1]               0\n",
      "      SmartConv2d-30             [-1, 10, 1, 1]           1,290\n",
      "          Flatten-31                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 413,578\n",
      "Trainable params: 413,578\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.33\n",
      "Params size (MB): 1.58\n",
      "Estimated Total Size (MB): 3.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T22:11:42.358060Z",
     "start_time": "2025-07-04T22:11:41.691769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dummy_input = torch.zeros(size=(1, 3, 32, 32), device=device)\n",
    "torch.onnx.export(network, dummy_input, \"/home/spometun/temp/resnet9small.onnx\")"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Detected that you are using FX to torch.jit.trace a dynamo-optimized function. This is not supported at the moment.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m dummy_input = torch.zeros(size=(\u001B[32m1\u001B[39m, \u001B[32m3\u001B[39m, \u001B[32m32\u001B[39m, \u001B[32m32\u001B[39m), device=device)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43monnx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexport\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnetwork\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdummy_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/home/spometun/temp/resnet9small.onnx\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/onnx/__init__.py:396\u001B[39m, in \u001B[36mexport\u001B[39m\u001B[34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, dynamic_axes, keep_initializers_as_inputs, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining)\u001B[39m\n\u001B[32m    390\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dynamic_shapes:\n\u001B[32m    391\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    392\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mThe exporter only supports dynamic shapes \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    393\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mthrough parameter dynamic_axes when dynamo=False.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    394\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m396\u001B[39m \u001B[43mexport\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    397\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    398\u001B[39m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    399\u001B[39m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[32m    400\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    401\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexport_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    402\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    403\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    404\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    405\u001B[39m \u001B[43m    \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[43m=\u001B[49m\u001B[43mopset_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    406\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    407\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    408\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    409\u001B[39m \u001B[43m    \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    410\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    411\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcustom_opsets\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcustom_opsets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    412\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    413\u001B[39m \u001B[43m    \u001B[49m\u001B[43mautograd_inlining\u001B[49m\u001B[43m=\u001B[49m\u001B[43mautograd_inlining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    414\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    415\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/onnx/utils.py:529\u001B[39m, in \u001B[36mexport\u001B[39m\u001B[34m(model, args, f, kwargs, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001B[39m\n\u001B[32m    526\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    527\u001B[39m     args = args + (kwargs,)\n\u001B[32m--> \u001B[39m\u001B[32m529\u001B[39m \u001B[43m_export\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    530\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    531\u001B[39m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    532\u001B[39m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    533\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    534\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    535\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    536\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    537\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    538\u001B[39m \u001B[43m    \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    539\u001B[39m \u001B[43m    \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[43m=\u001B[49m\u001B[43mopset_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    540\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    541\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    542\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    543\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcustom_opsets\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcustom_opsets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    544\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    545\u001B[39m \u001B[43m    \u001B[49m\u001B[43mautograd_inlining\u001B[49m\u001B[43m=\u001B[49m\u001B[43mautograd_inlining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    546\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    548\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/onnx/utils.py:1467\u001B[39m, in \u001B[36m_export\u001B[39m\u001B[34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001B[39m\n\u001B[32m   1464\u001B[39m     dynamic_axes = {}\n\u001B[32m   1465\u001B[39m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001B[32m-> \u001B[39m\u001B[32m1467\u001B[39m graph, params_dict, torch_out = \u001B[43m_model_to_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1468\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1469\u001B[39m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1470\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1471\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1472\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1473\u001B[39m \u001B[43m    \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1474\u001B[39m \u001B[43m    \u001B[49m\u001B[43mval_do_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1475\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfixed_batch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfixed_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1476\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1477\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1478\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1480\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m custom_opsets \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1481\u001B[39m     custom_opsets = {}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/onnx/utils.py:1087\u001B[39m, in \u001B[36m_model_to_graph\u001B[39m\u001B[34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001B[39m\n\u001B[32m   1084\u001B[39m     args = (args,)\n\u001B[32m   1086\u001B[39m model = _pre_trace_quant_model(model, args)\n\u001B[32m-> \u001B[39m\u001B[32m1087\u001B[39m graph, params, torch_out, module = \u001B[43m_create_jit_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1088\u001B[39m params_dict = _get_named_param_dict(graph, params)\n\u001B[32m   1090\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/onnx/utils.py:971\u001B[39m, in \u001B[36m_create_jit_graph\u001B[39m\u001B[34m(model, args)\u001B[39m\n\u001B[32m    966\u001B[39m     graph = _C._propagate_and_assign_input_shapes(\n\u001B[32m    967\u001B[39m         graph, flattened_args, param_count_list, \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    968\u001B[39m     )\n\u001B[32m    969\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m graph, params, torch_out, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m971\u001B[39m graph, torch_out = \u001B[43m_trace_and_get_graph_from_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    972\u001B[39m _C._jit_pass_onnx_lint(graph)\n\u001B[32m    973\u001B[39m state_dict = torch.jit._unique_state_dict(model)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/onnx/utils.py:878\u001B[39m, in \u001B[36m_trace_and_get_graph_from_model\u001B[39m\u001B[34m(model, args)\u001B[39m\n\u001B[32m    876\u001B[39m prev_autocast_cache_enabled = torch.is_autocast_cache_enabled()\n\u001B[32m    877\u001B[39m torch.set_autocast_cache_enabled(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m--> \u001B[39m\u001B[32m878\u001B[39m trace_graph, torch_out, inputs_states = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mjit\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_get_trace_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    880\u001B[39m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    881\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    882\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_force_outplace\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    883\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_return_inputs_states\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    884\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    885\u001B[39m torch.set_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001B[32m    887\u001B[39m warn_on_static_input_change(inputs_states)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838\u001B[39m, in \u001B[36mDisableContext.__call__.<locals>._fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    836\u001B[39m _maybe_set_eval_frame(_callback_from_stance(\u001B[38;5;28mself\u001B[39m.callback))\n\u001B[32m    837\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m838\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    839\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    840\u001B[39m     set_eval_frame(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/jit/_trace.py:1501\u001B[39m, in \u001B[36m_get_trace_graph\u001B[39m\u001B[34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001B[39m\n\u001B[32m   1499\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(args, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m   1500\u001B[39m     args = (args,)\n\u001B[32m-> \u001B[39m\u001B[32m1501\u001B[39m outs = \u001B[43mONNXTracedModule\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1502\u001B[39m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_force_outplace\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_return_inputs_states\u001B[49m\n\u001B[32m   1503\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1504\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m outs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/jit/_trace.py:138\u001B[39m, in \u001B[36mONNXTracedModule.forward\u001B[39m\u001B[34m(self, *args)\u001B[39m\n\u001B[32m    135\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    136\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m(out_vars)\n\u001B[32m--> \u001B[39m\u001B[32m138\u001B[39m graph, _out = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_C\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_create_graph_by_tracing\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    139\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwrapper\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    140\u001B[39m \u001B[43m    \u001B[49m\u001B[43min_vars\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_create_interpreter_name_lookup_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    142\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    143\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_force_outplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    144\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    146\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._return_inputs:\n\u001B[32m    147\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m graph, outs[\u001B[32m0\u001B[39m], ret_inputs[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/jit/_trace.py:129\u001B[39m, in \u001B[36mONNXTracedModule.forward.<locals>.wrapper\u001B[39m\u001B[34m(*args)\u001B[39m\n\u001B[32m    127\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._return_inputs_states:\n\u001B[32m    128\u001B[39m     inputs_states.append(_unflatten(in_args, in_desc))\n\u001B[32m--> \u001B[39m\u001B[32m129\u001B[39m outs.append(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mtrace_inputs\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m    130\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._return_inputs_states:\n\u001B[32m    131\u001B[39m     inputs_states[\u001B[32m0\u001B[39m] = (inputs_states[\u001B[32m0\u001B[39m], trace_inputs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:1741\u001B[39m, in \u001B[36mModule._slow_forward\u001B[39m\u001B[34m(self, *input, **kwargs)\u001B[39m\n\u001B[32m   1739\u001B[39m         recording_scopes = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m   1740\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1741\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1742\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m   1743\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m recording_scopes:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/home_project/livenet/v2/cifar_arch_smart.py:41\u001B[39m, in \u001B[36mResNet9SmallSmart.forward\u001B[39m\u001B[34m(self, xb)\u001B[39m\n\u001B[32m     40\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, xb):\n\u001B[32m---> \u001B[39m\u001B[32m41\u001B[39m     out = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     42\u001B[39m     out = \u001B[38;5;28mself\u001B[39m.conv2(out)\n\u001B[32m     43\u001B[39m     out = \u001B[38;5;28mself\u001B[39m.res1(out) + \u001B[38;5;28mself\u001B[39m.pick2(out)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:1741\u001B[39m, in \u001B[36mModule._slow_forward\u001B[39m\u001B[34m(self, *input, **kwargs)\u001B[39m\n\u001B[32m   1739\u001B[39m         recording_scopes = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m   1740\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1741\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1742\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m   1743\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m recording_scopes:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    238\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    239\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m240\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    241\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:1741\u001B[39m, in \u001B[36mModule._slow_forward\u001B[39m\u001B[34m(self, *input, **kwargs)\u001B[39m\n\u001B[32m   1739\u001B[39m         recording_scopes = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m   1740\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1741\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1742\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m   1743\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m recording_scopes:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/home_project/livenet/v2/smart_conv.py:53\u001B[39m, in \u001B[36mSmartConv2d.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01mcase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01m_\u001B[39;00m:\n\u001B[32m     52\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;28mself\u001B[39m.forward_type)\n\u001B[32m---> \u001B[39m\u001B[32m53\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_update_observation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     54\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:633\u001B[39m, in \u001B[36m_TorchDynamoContext.__call__.<locals>._fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    630\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m fn(*args, **kwargs)\n\u001B[32m    632\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_jit_tracing():\n\u001B[32m--> \u001B[39m\u001B[32m633\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m    634\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mDetected that you are using FX to torch.jit.trace \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    635\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33ma dynamo-optimized function. This is not supported at the moment.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    636\u001B[39m     )\n\u001B[32m    638\u001B[39m cleanups = [enter() \u001B[38;5;28;01mfor\u001B[39;00m enter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.enter_exit_hooks]\n\u001B[32m    639\u001B[39m prior_skip_guard_eval_unsafe = set_skip_guard_eval_unsafe(\n\u001B[32m    640\u001B[39m     _is_skip_guard_eval_unsafe_stance()\n\u001B[32m    641\u001B[39m )\n",
      "\u001B[31mRuntimeError\u001B[39m: Detected that you are using FX to torch.jit.trace a dynamo-optimized function. This is not supported at the moment."
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T22:11:55.449999Z",
     "start_time": "2025-07-04T22:11:55.419614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.set_printoptions(precision=3, suppress=True)\n",
    "ax_in = (0, 2, 3)\n",
    "ax_out = (1, 2, 3)\n",
    "ax = ax_out\n",
    "vals = list(network.parameters())[32].data.cpu().numpy()\n",
    "vals_ref = list(network.parameters())[32].data\n",
    "out_max = np.max(vals, axis=ax)\n",
    "out_min = np.min(vals, axis=ax)\n",
    "sign = -out_min > out_max\n",
    "out = np.max(np.abs(vals), axis=ax)\n",
    "#out *= 1 - sign * 2\n",
    "LOG(f\"{np.min(vals):.2f} {np.max(vals):.2f}\")\n",
    "print(np.sum(np.abs(vals) < 0.01), np.sum(np.abs(vals) > 0.0))\n",
    "#vals_ref[np.abs(vals) < 0.05] = 0.0\n",
    "out"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iˈ0.000 -2.20 2.44 \n",
      "0 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.328],\n",
       "       [2.198],\n",
       "       [1.562],\n",
       "       [1.313],\n",
       "       [1.115],\n",
       "       [1.513],\n",
       "       [2.438],\n",
       "       [0.728],\n",
       "       [0.172],\n",
       "       [2.01 ],\n",
       "       [0.105],\n",
       "       [1.246],\n",
       "       [1.509],\n",
       "       [0.133],\n",
       "       [0.887],\n",
       "       [0.139],\n",
       "       [1.583],\n",
       "       [2.142],\n",
       "       [2.178],\n",
       "       [0.776],\n",
       "       [0.075],\n",
       "       [2.079],\n",
       "       [0.808],\n",
       "       [1.608],\n",
       "       [1.654],\n",
       "       [2.066],\n",
       "       [0.074],\n",
       "       [1.721],\n",
       "       [1.738],\n",
       "       [0.084],\n",
       "       [0.825],\n",
       "       [1.399]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-04T22:12:34.533568Z",
     "start_time": "2025-07-04T22:12:34.111824Z"
    }
   },
   "source": [
    "criterion = livenet.nets.criterion_classification_n\n",
    "optimizer = livenet.nets.create_optimizer(network)\n",
    "trainer = livenet.net_trainer.NetTrainer(network, train_loader, criterion, optimizer)\n",
    "optimizer.learning_rate = 0.01\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T22:12:39.731299Z",
     "start_time": "2025-07-04T22:12:36.427093Z"
    }
   },
   "source": [
    "network.train()\n",
    "network.context.regularization_l1 = 1*1e-6\n",
    "trainer.step(5000)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iˈ0.000 195 2.950+0.000reg params=38 lr=0.01000 livenet/net_trainer.py:128\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mStopIteration\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/home_project/livenet/net_trainer.py:67\u001B[39m, in \u001B[36mNetTrainer._step\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     66\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m67\u001B[39m     data, labels = \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdata_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     68\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    732\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m733\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    734\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1480\u001B[39m, in \u001B[36m_MultiProcessingDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1479\u001B[39m         \u001B[38;5;28mself\u001B[39m._shutdown_workers()\n\u001B[32m-> \u001B[39m\u001B[32m1480\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[32m   1482\u001B[39m \u001B[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001B[39;00m\n\u001B[32m   1483\u001B[39m \n\u001B[32m   1484\u001B[39m \u001B[38;5;66;03m# Check if the next sample has already been generated\u001B[39;00m\n",
      "\u001B[31mStopIteration\u001B[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m network.train()\n\u001B[32m      2\u001B[39m network.context.regularization_l1 = \u001B[32m1\u001B[39m*\u001B[32m1e-6\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m5000\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/home_project/livenet/net_trainer.py:63\u001B[39m, in \u001B[36mNetTrainer.step\u001B[39m\u001B[34m(self, n_steps)\u001B[39m\n\u001B[32m     61\u001B[39m     LOG(\u001B[33m\"\u001B[39m\u001B[33mstopped\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     62\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/home_project/livenet/net_trainer.py:69\u001B[39m, in \u001B[36mNetTrainer._step\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     67\u001B[39m     data, labels = \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m.data_iter)\n\u001B[32m     68\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m69\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_on_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     70\u001B[39m     \u001B[38;5;28mself\u001B[39m.data_iter = \u001B[38;5;28miter\u001B[39m(\u001B[38;5;28mself\u001B[39m.data_loader)\n\u001B[32m     71\u001B[39m     data, labels = \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m.data_iter)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/home_project/livenet/net_trainer.py:129\u001B[39m, in \u001B[36mNetTrainer._on_epoch\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    126\u001B[39m         \u001B[38;5;28mself\u001B[39m._need_to_stop = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    128\u001B[39m LOG(msg)\n\u001B[32m--> \u001B[39m\u001B[32m129\u001B[39m m = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnetwork\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_stats_strs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclear\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    130\u001B[39m LOG(m)\n\u001B[32m    131\u001B[39m \u001B[38;5;28mself\u001B[39m.loss_criterion = \u001B[32m0.0\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/home_project/livenet/v2/cifar_arch_smart.py:67\u001B[39m, in \u001B[36mResNet9SmallSmart.get_stats_strs\u001B[39m\u001B[34m(self, clear)\u001B[39m\n\u001B[32m     65\u001B[39m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m     66\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m67\u001B[39m     m = \u001B[43mmodule\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_stats_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     68\u001B[39m     strs += \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfull_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mm\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     69\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m clear:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/home_project/livenet/v2/smart_conv.py:90\u001B[39m, in \u001B[36mSmartConv2d.get_stats_str\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     88\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_stats_str\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m     89\u001B[39m     kh, kw = \u001B[38;5;28mself\u001B[39m.kernel_size\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m     shape = (\u001B[38;5;28mself\u001B[39m.stats[\u001B[33m\"\u001B[39m\u001B[33mcount\u001B[39m\u001B[33m\"\u001B[39m], \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstats\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mbatch_size\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m, \u001B[38;5;28mself\u001B[39m.groups, \u001B[38;5;28mself\u001B[39m.in_channels // \u001B[38;5;28mself\u001B[39m.groups, kh, kw, \u001B[38;5;28mself\u001B[39m.stats[\u001B[33m\"\u001B[39m\u001B[33mout_h\u001B[39m\u001B[33m\"\u001B[39m], \u001B[38;5;28mself\u001B[39m.stats[\u001B[33m\"\u001B[39m\u001B[33mout_w\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m     91\u001B[39m     sum_ = \u001B[38;5;28mself\u001B[39m.stats[\u001B[33m\"\u001B[39m\u001B[33mops_amount_sum\u001B[39m\u001B[33m\"\u001B[39m].sum().cpu().item()\n\u001B[32m     92\u001B[39m     ratio = sum_ / math.prod(shape)\n",
      "\u001B[31mKeyError\u001B[39m: 'batch_size'"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T00:41:22.859561Z",
     "start_time": "2025-05-26T00:40:36.648319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def _infer_epoch(network, loader):\n",
    "    preds = []\n",
    "    ys = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in iter(loader):\n",
    "            x = x.to(network.device)\n",
    "            pred = network(x)\n",
    "            pred = pred.cpu()\n",
    "            preds.append(pred)\n",
    "            ys.append(y.cpu())\n",
    "    pred = torch.concatenate(preds)\n",
    "    y = torch.concatenate(ys)\n",
    "    return pred, y\n",
    "\n",
    "\n",
    "network.train()\n",
    "#train_pred, train_labels = _infer_epoch(network, train_loader)\n",
    "test_pred, test_labels = _infer_epoch(network, test_loader)\n",
    "\n",
    "network.eval()\n",
    "test_pred, test_labels = _infer_epoch(network, test_loader)\n",
    "train_pred, train_labels = _infer_epoch(network, train_loader)\n",
    "\n",
    "def calc_accuracy(predictions, labels):\n",
    "    _, predicted = torch.max(predictions.data, 1)\n",
    "    labels = labels.numpy()\n",
    "    labels = np.squeeze(labels, 1)\n",
    "    predicted = predicted.numpy()\n",
    "    correct = np.sum(predicted == labels)\n",
    "    total = len(labels)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# test_y_tensor = torch.tensor(test_y, device=\"cpu\")\n",
    "# train_y_tensor = torch.tensor(train_y, device=\"cpu\")\n",
    "test_loss = trainer.criterion(test_pred, test_labels).item()\n",
    "train_loss = trainer.criterion(train_pred, train_labels).item()\n",
    "LOG(f\"loss: train: {train_loss:.3f} test: {test_loss:.3f}\")\n",
    "\n",
    "test_accuracy = calc_accuracy(test_pred, test_labels)\n",
    "train_accuracy = calc_accuracy(train_pred, train_labels)\n",
    "LOG(f\"accuracy, train: {100 * train_accuracy:.1f}% test: {100 * test_accuracy:.1f}%\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spometun/miniconda3/envs/home/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:236: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n",
      "W0525 20:40:38.197000 90479 site-packages/torch/_inductor/utils.py:1250] [0/5] Not enough SMs to use max_autotune_gemm mode\n",
      "W0525 20:41:13.684000 90479 site-packages/torch/_dynamo/convert_frame.py:964] [0/8] torch._dynamo hit config.recompile_limit (8)\n",
      "W0525 20:41:13.684000 90479 site-packages/torch/_dynamo/convert_frame.py:964] [0/8]    function: 'forward' (/home/spometun/projects/home_project/livenet/v2/smart_conv.py:42)\n",
      "W0525 20:41:13.684000 90479 site-packages/torch/_dynamo/convert_frame.py:964] [0/8]    last reason: 0/7: tensor 'self.stats['ops_amount_sum']' size mismatch at index 0. expected 128, actual 1\n",
      "W0525 20:41:13.684000 90479 site-packages/torch/_dynamo/convert_frame.py:964] [0/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W0525 20:41:13.684000 90479 site-packages/torch/_dynamo/convert_frame.py:964] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iˈ0.000 loss: train: 1.037 test: 0.644 \n",
      "Iˈ0.001 accuracy, train: 75.2% test: 84.5% \n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "network.to(\"cpu\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param = list(network.named_parameters())\n",
    "param0 = list(network.parameters())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "w = param[12][1].detach().cpu().numpy()\n",
    "m = np.max(np.abs(w), axis=(1, 2, 3))\n",
    "f\"{int(100 * np.sum(m > 0.01) / len(m))}%\"\n",
    "np.sum(m > 0.01)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "outs = dict()\n",
    "for i in range(11):\n",
    "    ind = i * 4\n",
    "    if ind >= 36:\n",
    "        ind = 32 + (i - 8)\n",
    "    w = param[ind][1].detach().cpu().numpy()\n",
    "    w_name = param[ind][0]\n",
    "    m_out = np.max(np.abs(w), axis=(1, 2, 3))\n",
    "    outs[ind] = m_out > 0.01\n",
    "    m_in = np.max(np.abs(w), axis=(0, 2, 3))\n",
    "    n_out = np.sum(m_out > 0.01)\n",
    "    n_in = np.sum(m_in > 0.01)\n",
    "    s = f\"{w_name} {ind}, {w.shape} {int(100 * np.sum(m_out > 0.01) / len(m_out))}%, {n_in}->{n_out}\"\n",
    "    print(s)\n",
    "for ind in [12, 28]:\n",
    "    ind2 = 32 if ind == 12 else 33\n",
    "    n_inter = np.sum(outs[ind] * outs[ind2])\n",
    "    print(f\"{ind} inter={n_inter}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np.set_printoptions(1)\n",
    "w = param[12][1].detach().cpu().numpy()\n",
    "wa = np.abs(w)\n",
    "wa_max = np.max(wa, axis=(1, 2, 3))\n",
    "i = np.argsort(wa_max)[::-1]\n",
    "f = w[i[0]]\n",
    "fa = np.abs(f)\n",
    "fa_max = np.max(fa, axis=(1, 2))\n",
    "#print(f\"{wa_max[i]}\")\n",
    "# print(wa[i].shape)\n",
    "i1 = np.argsort(fa_max)[::-1]\n",
    "f1b = fa > 0.1\n",
    "np.sum(f1b)\n",
    "f[i1[2]]\n",
    "# fa[69]\n",
    "#f[i1]"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
