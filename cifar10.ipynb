{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-11T14:37:35.484303Z",
     "start_time": "2025-05-11T14:37:35.465410Z"
    }
   },
   "source": [
    "# TODO:\n",
    "# reprodicible results driven by seed\n",
    "# correlation of features output for two networks. Or even FC training from from to other with L1/L2 norm?\n",
    "# start develop liveconv\n",
    "# don't forger penalise for operation, not (just) weight. Add stats on operations\n",
    "# why features' weights small but not zero? should I try depth-separable conv?\n",
    "# manual livenet for cifar10, and then think on auto?\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torchsummary\n",
    "import numpy as np\n",
    "import gc\n",
    "from livenet.utils import set_seed\n",
    "import onnx\n",
    "import livenet\n",
    "device = \"cuda\"\n",
    "#device = \"cpu\"\n",
    "#torch.set_default_device(device)\n",
    "from ai_libs.simple_log import LOG\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T22:33:44.363288Z",
     "start_time": "2025-05-11T22:33:39.243913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 256\n",
    "from livenet.datasets import TransformDataset\n",
    "test_x, test_y = livenet.datasets.get_cifar10_test()\n",
    "test = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "test_aug = TransformDataset(test, livenet.datasets.cifar10_test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_aug, batch_size=batch_size, drop_last=True, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "train_x, train_y = livenet.datasets.get_cifar10_train()\n",
    "train = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "train_aug = TransformDataset(train, livenet.datasets.cifar10_train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_aug, batch_size=batch_size, drop_last=True, shuffle=True, num_workers=16, pin_memory=True, prefetch_factor=2)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T20:39:15.501728Z",
     "start_time": "2025-05-10T20:39:15.481505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "train_aug = TransformDataset(train, livenet.datasets.cifar10_train_transform)\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T20:39:19.962165Z",
     "start_time": "2025-05-10T20:39:19.905073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img = train_aug[4][0].numpy()\n",
    "img = img.transpose(1, 2, 0)\n",
    "from matplotlib import pyplot as plt\n",
    "#img = livenet.datasets._elastic_transform(img, (-4, 0))\n",
    "img = (img * 128 + 127).astype(np.uint8)\n",
    "\n",
    "#plt.imsave(\"/home/spometun/img.png\", img)\n",
    "plt.imshow( img )"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x74ec743dc080>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-12T01:35:58.126987Z",
     "start_time": "2025-05-12T01:35:58.067993Z"
    }
   },
   "source": [
    "from cifar_arch import EffNet, ResNet9, ResNet9Small\n",
    "\n",
    "set_seed(2)\n",
    "\n",
    "# network = EffNet(device)\n",
    "network = ResNet9Small(3, 10, device)\n",
    "torchsummary.summary(network, (3, 32, 32), device=device)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             448\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "             ReLU6-3           [-1, 16, 32, 32]               0\n",
      "            Conv2d-4           [-1, 32, 32, 32]           4,640\n",
      "       BatchNorm2d-5           [-1, 32, 32, 32]              64\n",
      "             ReLU6-6           [-1, 32, 32, 32]               0\n",
      "         MaxPool2d-7           [-1, 32, 16, 16]               0\n",
      "            Conv2d-8           [-1, 32, 16, 16]           9,248\n",
      "       BatchNorm2d-9           [-1, 32, 16, 16]              64\n",
      "            ReLU6-10           [-1, 32, 16, 16]               0\n",
      "           Conv2d-11           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-12           [-1, 32, 16, 16]              64\n",
      "            ReLU6-13           [-1, 32, 16, 16]               0\n",
      "           Conv2d-14           [-1, 32, 16, 16]              32\n",
      "           Conv2d-15           [-1, 64, 16, 16]          18,496\n",
      "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
      "            ReLU6-17           [-1, 64, 16, 16]               0\n",
      "        MaxPool2d-18             [-1, 64, 8, 8]               0\n",
      "           Conv2d-19            [-1, 128, 8, 8]          73,856\n",
      "      BatchNorm2d-20            [-1, 128, 8, 8]             256\n",
      "            ReLU6-21            [-1, 128, 8, 8]               0\n",
      "        MaxPool2d-22            [-1, 128, 4, 4]               0\n",
      "           Conv2d-23            [-1, 128, 4, 4]         147,584\n",
      "      BatchNorm2d-24            [-1, 128, 4, 4]             256\n",
      "            ReLU6-25            [-1, 128, 4, 4]               0\n",
      "           Conv2d-26            [-1, 128, 4, 4]         147,584\n",
      "      BatchNorm2d-27            [-1, 128, 4, 4]             256\n",
      "            ReLU6-28            [-1, 128, 4, 4]               0\n",
      "           Conv2d-29            [-1, 128, 4, 4]             128\n",
      "        MaxPool2d-30            [-1, 128, 1, 1]               0\n",
      "           Conv2d-31             [-1, 10, 1, 1]           1,290\n",
      "          Flatten-32                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 413,674\n",
      "Trainable params: 413,674\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.34\n",
      "Params size (MB): 1.58\n",
      "Estimated Total Size (MB): 3.93\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T22:34:14.088154Z",
     "start_time": "2025-05-11T22:34:14.063417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.set_printoptions(precision=1)\n",
    "vals = list(network.parameters())[33].data.cpu().numpy().squeeze()\n",
    "LOG(f\"{np.min(vals):.2f} {np.max(vals):.2f}\")\n",
    "print(np.sum(vals < 0.01), np.sum(vals > 0.2))\n",
    "vals"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iˈ0.000 -0.99 0.98 \n",
      "65 51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.4,  0.4,  0.1,  0.9, -0. , -0. ,  0.4, -0.4, -0.6, -0.5,  0.7,\n",
       "        0.1, -0.9,  0.7, -0.6,  0.2, -0.3,  0.5, -0.3,  0.5,  0.2, -0.6,\n",
       "        0.6, -0.3, -0.3,  0.7, -0. , -0.7, -0. ,  0.7,  0.4,  0.8,  0.1,\n",
       "        0.8, -0.4, -0.3, -0.3, -0.7, -0.6,  0.6, -0.3, -0.1, -0.1, -0.1,\n",
       "       -0.4,  0.9, -0.3,  0.3, -0.9, -0.9,  0.8, -0.2, -0.3, -1. ,  0.1,\n",
       "       -0.4, -0. ,  0. , -1. ,  0.3,  0.7,  0.7,  0.8,  0.9,  0.1,  0.9,\n",
       "        0.5,  1. , -0.6, -0.5, -0.2,  0.9,  0.6,  0.5, -0.8,  0.3, -0. ,\n",
       "        0.8, -0.1, -0.2, -0.9, -0.1, -0. ,  0.9, -0.3,  0.4,  0.8,  0.7,\n",
       "        0.1, -0.5, -0. , -0.2, -0.6, -0.8,  0.4,  0.8,  0.1, -0.2, -0.5,\n",
       "        0.7, -0.6,  0.4, -0.3, -0.8, -0.9, -0.1,  0.8,  0.8, -0. ,  0.2,\n",
       "        0.7,  0.3, -0.6,  0.5, -0.4, -0.2,  0.5,  0.1, -0.3,  0.4,  0.9,\n",
       "        0.1, -0.8,  0.3,  0.5, -0.2,  0.8,  0.9], dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 145
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-12T01:36:02.954302Z",
     "start_time": "2025-05-12T01:36:02.308188Z"
    }
   },
   "source": [
    "criterion = livenet.nets.criterion_classification_n\n",
    "optimizer = livenet.nets.create_optimizer(network)\n",
    "trainer = livenet.net_trainer.NetTrainer(network, train_loader, criterion, optimizer)\n",
    "trainer.adaptive_lr = True\n",
    "optimizer.learning_rate = 0.01\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n"
     ]
    }
   ],
   "execution_count": 166
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T01:56:28.740787Z",
     "start_time": "2025-05-12T01:36:04.567156Z"
    }
   },
   "source": [
    "network.train()\n",
    "#trainer._need_to_stop = False\n",
    "#trainer.optimizer.learning_rate = 0.01 / 2 / 2 / 2 / 2 /2/2\n",
    "network._alpha = 0.01 * 1e-6\n",
    "trainer.step(30000)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iˈ0.000 194 2.909+0.012reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ6.502 389 2.161+0.025reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ13.336 584 1.784+0.034reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ20.147 779 1.563+0.041reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ27.062 974 1.430+0.046reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ34.102 1169 1.338+0.051reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ41.245 1364 1.264+0.055reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ48.265 1559 1.212+0.059reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ55.523 1754 1.161+0.062reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ62.913 1949 1.128+0.066reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ70.475 2144 1.100+0.069reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ78.041 2339 1.049+0.072reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ85.716 2534 1.034+0.074reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ93.076 2729 1.015+0.077reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ100.465 2924 0.999+0.079reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ108.214 3119 0.967+0.082reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ115.598 3314 0.950+0.084reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ123.055 3509 0.936+0.086reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ130.912 3704 0.925+0.088reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ138.714 3899 0.904+0.090reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ146.783 4094 0.891+0.091reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ154.776 4289 0.883+0.093reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ162.466 4484 0.871+0.095reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ170.485 4679 0.857+0.097reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ178.116 4874 0.846+0.098reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ185.785 5069 0.833+0.100reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ193.696 5264 0.828+0.101reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ201.729 5459 0.820+0.103reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ209.669 5654 0.809+0.104reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ217.869 5849 0.801+0.106reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ225.851 6044 0.792+0.107reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ233.773 6239 0.793+0.108reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ242.213 6434 0.785+0.109reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ250.069 6629 0.776+0.111reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ258.284 6824 0.763+0.112reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ266.377 7019 0.763+0.113reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ274.249 7214 0.755+0.114reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ282.395 7409 0.755+0.116reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ290.471 7604 0.750+0.117reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ298.767 7799 0.739+0.118reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ307.079 7994 0.739+0.119reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ314.996 8189 0.727+0.120reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ323.440 8384 0.730+0.121reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ331.366 8579 0.718+0.122reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ339.306 8774 0.718+0.123reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ347.048 8969 0.707+0.124reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ354.850 9164 0.708+0.125reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ363.049 9359 0.705+0.125reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ371.150 9554 0.700+0.126reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ379.295 9749 0.703+0.127reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ387.129 9944 0.682+0.128reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ394.975 10139 0.687+0.129reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ402.862 10334 0.690+0.130reg params=36 lr=0.01000 livenet/net_trainer.py:134\n",
      "Iˈ410.751 10529 0.687+0.131reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ418.915 10724 0.610+0.131reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ426.695 10919 0.594+0.131reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ435.041 11114 0.598+0.130reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ443.063 11309 0.592+0.130reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ450.803 11504 0.583+0.130reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ459.053 11699 0.578+0.130reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ467.188 11894 0.578+0.130reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ475.305 12089 0.571+0.130reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ483.742 12284 0.573+0.130reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ491.395 12479 0.567+0.130reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ499.411 12674 0.567+0.130reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ507.739 12869 0.563+0.130reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ516.007 13064 0.560+0.130reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ523.762 13259 0.566+0.130reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ531.703 13454 0.557+0.129reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ539.675 13649 0.554+0.129reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ547.901 13844 0.553+0.129reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ555.998 14039 0.562+0.129reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ563.968 14234 0.554+0.129reg params=36 lr=0.00500 livenet/net_trainer.py:134\n",
      "Iˈ572.231 14429 0.558+0.130reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ580.469 14624 0.520+0.129reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ588.417 14819 0.502+0.129reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ596.550 15014 0.508+0.129reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ604.814 15209 0.502+0.129reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ612.879 15404 0.502+0.129reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ620.733 15599 0.503+0.128reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ628.609 15794 0.495+0.128reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ636.470 15989 0.497+0.128reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ644.783 16184 0.495+0.128reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ652.701 16379 0.493+0.128reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ660.653 16574 0.491+0.128reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ668.669 16769 0.494+0.128reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ676.853 16964 0.490+0.127reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ684.781 17159 0.489+0.127reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ692.821 17354 0.487+0.127reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ701.202 17549 0.494+0.127reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ709.054 17744 0.491+0.127reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ716.882 17939 0.483+0.127reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ724.712 18134 0.475+0.127reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ732.718 18329 0.481+0.127reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ740.785 18524 0.479+0.127reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ748.757 18719 0.475+0.126reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ756.903 18914 0.489+0.126reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ765.354 19109 0.475+0.126reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ773.457 19304 0.482+0.126reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ781.418 19499 0.477+0.126reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ789.712 19694 0.473+0.126reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ797.779 19889 0.480+0.126reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ805.897 20084 0.467+0.126reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ814.101 20279 0.474+0.126reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ822.688 20474 0.465+0.126reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ830.612 20669 0.472+0.125reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ838.689 20864 0.460+0.125reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ846.841 21059 0.473+0.125reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ854.841 21254 0.467+0.125reg params=36 lr=0.00250 livenet/net_trainer.py:134\n",
      "Iˈ863.049 21449 0.466+0.125reg params=36 lr=0.00125 livenet/net_trainer.py:134\n",
      "Iˈ871.087 21644 0.451+0.125reg params=36 lr=0.00125 livenet/net_trainer.py:134\n",
      "Iˈ879.336 21839 0.448+0.125reg params=36 lr=0.00125 livenet/net_trainer.py:134\n",
      "Iˈ887.125 22034 0.443+0.125reg params=36 lr=0.00125 livenet/net_trainer.py:134\n",
      "Iˈ895.079 22229 0.447+0.125reg params=36 lr=0.00125 livenet/net_trainer.py:134\n",
      "Iˈ903.033 22424 0.445+0.125reg params=36 lr=0.00125 livenet/net_trainer.py:134\n",
      "Iˈ911.041 22619 0.443+0.124reg params=36 lr=0.00125 livenet/net_trainer.py:134\n",
      "Iˈ919.478 22814 0.440+0.124reg params=36 lr=0.00125 livenet/net_trainer.py:134\n",
      "Iˈ927.562 23009 0.446+0.124reg params=36 lr=0.00125 livenet/net_trainer.py:134\n",
      "Iˈ935.584 23204 0.440+0.124reg params=36 lr=0.00125 livenet/net_trainer.py:134\n",
      "Iˈ943.788 23399 0.441+0.124reg params=36 lr=0.00125 livenet/net_trainer.py:134\n",
      "Iˈ951.808 23594 0.441+0.124reg params=36 lr=0.00125 livenet/net_trainer.py:134\n",
      "Iˈ959.738 23789 0.440+0.124reg params=36 lr=0.00063 livenet/net_trainer.py:134\n",
      "Iˈ967.945 23984 0.431+0.124reg params=36 lr=0.00063 livenet/net_trainer.py:134\n",
      "Iˈ975.806 24179 0.434+0.124reg params=36 lr=0.00063 livenet/net_trainer.py:134\n",
      "Iˈ984.099 24374 0.437+0.124reg params=36 lr=0.00063 livenet/net_trainer.py:134\n",
      "Iˈ992.240 24569 0.427+0.124reg params=36 lr=0.00063 livenet/net_trainer.py:134\n",
      "Iˈ1000.463 24764 0.427+0.124reg params=36 lr=0.00063 livenet/net_trainer.py:134\n",
      "Iˈ1008.589 24959 0.426+0.124reg params=36 lr=0.00063 livenet/net_trainer.py:134\n",
      "Iˈ1016.999 25154 0.430+0.123reg params=36 lr=0.00063 livenet/net_trainer.py:134\n",
      "Iˈ1024.870 25349 0.422+0.123reg params=36 lr=0.00063 livenet/net_trainer.py:134\n",
      "Iˈ1033.247 25544 0.421+0.123reg params=36 lr=0.00063 livenet/net_trainer.py:134\n",
      "Iˈ1041.448 25739 0.425+0.123reg params=36 lr=0.00063 livenet/net_trainer.py:134\n",
      "Iˈ1049.559 25934 0.429+0.123reg params=36 lr=0.00063 livenet/net_trainer.py:134\n",
      "Iˈ1057.734 26129 0.429+0.123reg params=36 lr=0.00031 livenet/net_trainer.py:134\n",
      "Iˈ1065.877 26324 0.420+0.123reg params=36 lr=0.00031 livenet/net_trainer.py:134\n",
      "Iˈ1074.098 26519 0.417+0.123reg params=36 lr=0.00031 livenet/net_trainer.py:134\n",
      "Iˈ1082.268 26714 0.421+0.123reg params=36 lr=0.00031 livenet/net_trainer.py:134\n",
      "Iˈ1090.224 26909 0.420+0.123reg params=36 lr=0.00031 livenet/net_trainer.py:134\n",
      "Iˈ1098.257 27104 0.419+0.123reg params=36 lr=0.00031 livenet/net_trainer.py:134\n",
      "Iˈ1106.562 27299 0.422+0.123reg params=36 lr=0.00016 livenet/net_trainer.py:134\n",
      "Iˈ1114.594 27494 0.419+0.123reg params=36 lr=0.00016 livenet/net_trainer.py:134\n",
      "Iˈ1122.694 27689 0.416+0.123reg params=36 lr=0.00016 livenet/net_trainer.py:134\n",
      "Iˈ1130.676 27884 0.420+0.123reg params=36 lr=0.00016 livenet/net_trainer.py:134\n",
      "Iˈ1139.055 28079 0.412+0.123reg params=36 lr=0.00016 livenet/net_trainer.py:134\n",
      "Iˈ1147.154 28274 0.419+0.123reg params=36 lr=0.00016 livenet/net_trainer.py:134\n",
      "Iˈ1155.293 28469 0.414+0.123reg params=36 lr=0.00016 livenet/net_trainer.py:134\n",
      "Iˈ1163.281 28664 0.409+0.123reg params=36 lr=0.00016 livenet/net_trainer.py:134\n",
      "Iˈ1171.507 28859 0.422+0.123reg params=36 lr=0.00016 livenet/net_trainer.py:134\n",
      "Iˈ1179.490 29054 0.413+0.123reg params=36 lr=0.00016 livenet/net_trainer.py:134\n",
      "Iˈ1187.729 29249 0.423+0.123reg params=36 lr=0.00008 livenet/net_trainer.py:134\n",
      "Iˈ1195.948 29444 0.415+0.123reg params=36 lr=0.00008 livenet/net_trainer.py:134\n",
      "Iˈ1203.824 29639 0.415+0.123reg params=36 lr=0.00008 livenet/net_trainer.py:134\n",
      "Iˈ1211.967 29834 0.414+0.123reg params=36 lr=0.00008 livenet/net_trainer.py:134\n"
     ]
    }
   ],
   "execution_count": 167
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:23:56.149483Z",
     "start_time": "2025-05-12T11:23:55.805884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def _infer_epoch(network, loader):\n",
    "    preds = []\n",
    "    ys = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in iter(loader):\n",
    "            x = x.to(network.device)\n",
    "            pred = network(x)\n",
    "            pred = pred.cpu()\n",
    "            preds.append(pred)\n",
    "            ys.append(y.cpu())\n",
    "    pred = torch.concatenate(preds)\n",
    "    y = torch.concatenate(ys)\n",
    "    return pred, y\n",
    "\n",
    "\n",
    "network.train()\n",
    "#train_pred, train_labels = _infer_epoch(network, train_loader)\n",
    "test_pred, test_labels = _infer_epoch(network, test_loader)\n",
    "\n",
    "network.eval()\n",
    "test_pred, test_labels = _infer_epoch(network, test_loader)\n",
    "train_pred, train_labels = _infer_epoch(network, train_loader)\n",
    "\n",
    "def calc_accuracy(predictions, labels):\n",
    "    _, predicted = torch.max(predictions.data, 1)\n",
    "    labels = labels.numpy()\n",
    "    labels = np.squeeze(labels, 1)\n",
    "    predicted = predicted.numpy()\n",
    "    correct = np.sum(predicted == labels)\n",
    "    total = len(labels)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# test_y_tensor = torch.tensor(test_y, device=\"cpu\")\n",
    "# train_y_tensor = torch.tensor(train_y, device=\"cpu\")\n",
    "test_loss = trainer.criterion(test_pred, test_labels).item()\n",
    "train_loss = trainer.criterion(train_pred, train_labels).item()\n",
    "LOG(f\"loss: train: {train_loss:.3f} test: {test_loss:.3f}\")\n",
    "\n",
    "test_accuracy = calc_accuracy(test_pred, test_labels)\n",
    "train_accuracy = calc_accuracy(train_pred, train_labels)\n",
    "LOG(f\"accuracy, train: {100 * train_accuracy:.1f}% test: {100 * test_accuracy:.1f}%\")"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[168]\u001B[39m\u001B[32m, line 21\u001B[39m\n\u001B[32m     19\u001B[39m network.train()\n\u001B[32m     20\u001B[39m \u001B[38;5;66;03m#train_pred, train_labels = _infer_epoch(network, train_loader)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m test_pred, test_labels = \u001B[43m_infer_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnetwork\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     23\u001B[39m network.eval()\n\u001B[32m     24\u001B[39m test_pred, test_labels = _infer_epoch(network, test_loader)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[168]\u001B[39m\u001B[32m, line 9\u001B[39m, in \u001B[36m_infer_epoch\u001B[39m\u001B[34m(network, loader)\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m      8\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m x, y \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28miter\u001B[39m(loader):\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m         x = \u001B[43mx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnetwork\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m         pred = network(x)\n\u001B[32m     11\u001B[39m         pred = pred.cpu()\n",
      "\u001B[31mRuntimeError\u001B[39m: CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:25:09.593366Z",
     "start_time": "2025-05-12T11:25:09.506572Z"
    }
   },
   "cell_type": "code",
   "source": "network.to(\"cpu\")",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[169]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mnetwork\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcpu\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:1355\u001B[39m, in \u001B[36mModule.to\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1352\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1353\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1355\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    913\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[32m    914\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.children():\n\u001B[32m--> \u001B[39m\u001B[32m915\u001B[39m         \u001B[43mmodule\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[32m    918\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[32m    919\u001B[39m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[32m    920\u001B[39m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    925\u001B[39m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[32m    926\u001B[39m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    913\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[32m    914\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.children():\n\u001B[32m--> \u001B[39m\u001B[32m915\u001B[39m         \u001B[43mmodule\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[32m    918\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[32m    919\u001B[39m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[32m    920\u001B[39m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    925\u001B[39m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[32m    926\u001B[39m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:942\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    938\u001B[39m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[32m    939\u001B[39m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[32m    940\u001B[39m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[32m    941\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m--> \u001B[39m\u001B[32m942\u001B[39m     param_applied = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    943\u001B[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001B[32m    945\u001B[39m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/home/lib/python3.12/site-packages/torch/nn/modules/module.py:1341\u001B[39m, in \u001B[36mModule.to.<locals>.convert\u001B[39m\u001B[34m(t)\u001B[39m\n\u001B[32m   1334\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t.dim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[32m4\u001B[39m, \u001B[32m5\u001B[39m):\n\u001B[32m   1335\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m t.to(\n\u001B[32m   1336\u001B[39m             device,\n\u001B[32m   1337\u001B[39m             dtype \u001B[38;5;28;01mif\u001B[39;00m t.is_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t.is_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1338\u001B[39m             non_blocking,\n\u001B[32m   1339\u001B[39m             memory_format=convert_to_format,\n\u001B[32m   1340\u001B[39m         )\n\u001B[32m-> \u001B[39m\u001B[32m1341\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1342\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1343\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1344\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1345\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1346\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m   1347\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) == \u001B[33m\"\u001B[39m\u001B[33mCannot copy out of meta tensor; no data!\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[31mRuntimeError\u001B[39m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T15:35:22.878105Z",
     "start_time": "2025-05-11T15:35:22.863725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param = list(network.named_parameters())\n",
    "param0 = list(network.parameters())\n"
   ],
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T00:36:20.260784Z",
     "start_time": "2025-05-04T00:36:20.246898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w = param[12][1].detach().cpu().numpy()\n",
    "m = np.max(np.abs(w), axis=(1, 2, 3))\n",
    "f\"{int(100 * np.sum(m > 0.01) / len(m))}%\"\n",
    "np.sum(m > 0.01)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(12)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 236
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T23:25:28.597744Z",
     "start_time": "2025-05-10T23:25:28.581472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outs = dict()\n",
    "for i in range(9):\n",
    "    ind = i * 4\n",
    "    w = param[ind][1].detach().cpu().numpy()\n",
    "    m_out = np.max(np.abs(w), axis=(1, 2, 3))\n",
    "    outs[ind] = m_out > 0.01\n",
    "    m_in = np.max(np.abs(w), axis=(0, 2, 3))\n",
    "    n_out = np.sum(m_out > 0.01)\n",
    "    n_in = np.sum(m_in > 0.01)\n",
    "    s = f\"{ind}, {w.shape} {int(100 * np.sum(m_out > 0.01) / len(m_out))}%, {n_in}->{n_out}\"\n",
    "    if ind in [12, 28]:\n",
    "        n_inter = np.sum(outs[ind - 8] * outs[ind])\n",
    "        s += f\" inter={n_inter}\"\n",
    "    print(s)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, (16, 3, 3, 3) 87%, 3->14\n",
      "4, (32, 16, 3, 3) 87%, 14->28\n",
      "8, (32, 32, 3, 3) 0%, 0->0\n",
      "12, (32, 32, 3, 3) 0%, 0->0 inter=0\n",
      "16, (64, 32, 3, 3) 100%, 28->64\n",
      "20, (128, 64, 3, 3) 95%, 64->122\n",
      "24, (128, 128, 3, 3) 0%, 0->0\n",
      "28, (128, 128, 3, 3) 0%, 0->0 inter=0\n",
      "32, (10, 128, 1, 1) 100%, 122->10\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T01:23:14.689054Z",
     "start_time": "2025-05-05T01:23:14.655084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.set_printoptions(1)\n",
    "w = param[12][1].detach().cpu().numpy()\n",
    "wa = np.abs(w)\n",
    "wa_max = np.max(wa, axis=(1, 2, 3))\n",
    "i = np.argsort(wa_max)[::-1]\n",
    "f = w[i[0]]\n",
    "fa = np.abs(f)\n",
    "fa_max = np.max(fa, axis=(1, 2))\n",
    "#print(f\"{wa_max[i]}\")\n",
    "# print(wa[i].shape)\n",
    "i1 = np.argsort(fa_max)[::-1]\n",
    "f1b = fa > 0.1\n",
    "np.sum(f1b)\n",
    "f[i1[2]]\n",
    "# fa[69]\n",
    "#f[i1]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.4e-02,  5.9e-03,  1.4e-03],\n",
       "       [-2.8e-05, -2.1e-01, -1.1e-04],\n",
       "       [-6.2e-03, -4.6e-02,  2.4e-02]], dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 185
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
