{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-23T15:15:35.211029Z",
     "start_time": "2025-03-23T15:15:32.879414Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torchsummary\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from livenet.backend.core import Context\n",
    "import random\n",
    "import importlib\n",
    "import onnx\n",
    "import livenet\n",
    "device = \"cuda\"\n",
    "# device = \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "from ai_libs.simple_log import LOG\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-23T15:15:54.408411Z",
     "start_time": "2025-03-23T15:15:38.165292Z"
    }
   },
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor()\n",
    "#         ,transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#      ])\n",
    "# train=torchvision.datasets.CIFAR10(\"/home/spometun/datasets/research\", train=True,\n",
    "#                                   download=True, transform=transform)\n",
    "# test=torchvision.datasets.CIFAR10(\"/home/spometun/datasets/research\", train=False,\n",
    "#                                   download=True, transform=transform)\n",
    "#\n",
    "#\n",
    "# def get_whole_data(dataset):\n",
    "#     loader = torch.utils.data.DataLoader(dataset, batch_size=len(dataset))\n",
    "#     data = next(iter(loader))\n",
    "#     data[0] = data[0].to(device)\n",
    "#     data[1] = data[1].to(device)\n",
    "#     return data\n",
    "#\n",
    "# test_whole_data = get_whole_data(test)\n",
    "# train_whole_data = get_whole_data(train)\n",
    "\n",
    "# test_x, test_y = test_whole_data\n",
    "# train_x, train_y = train_whole_data\n",
    "\n",
    "test_x, test_y = livenet.datasets.get_cifar10_test()\n",
    "train_x, train_y = livenet.datasets.get_cifar10_train()\n",
    "\n",
    "test_x = test_x.to(device)\n",
    "test_y = test_y.to(device)\n",
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-23T15:33:25.391409Z",
     "start_time": "2025-03-23T15:33:25.370520Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed(0)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.context = Context(self)\n",
    "        self.max_pool = nn.MaxPool2d(2, 2)\n",
    "        self.av_pool = nn.AvgPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3)\n",
    "        self.conv2 = nn.Conv2d(8, 8, 3,padding=\"same\")\n",
    "        self.conv3 = nn.Conv2d(16, 16, 3,padding=\"same\")\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.fc = nn.Linear(8*7*7,10)\n",
    "        self._alpha = 0.0001\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = F.relu(self.conv1(x))\n",
    "        # x = self.max_pool(x)\n",
    "        x = self.av_pool(x)\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.max_pool(x)\n",
    "        # x = self.pool(x)\n",
    "        # x = F.relu(self.conv3(x))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        # x = self.fc3(x)\n",
    "        x=self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def internal_loss(self):\n",
    "        loss = torch.tensor(0.)\n",
    "        for param in self.parameters():\n",
    "            if len(param.data.shape) > 1:\n",
    "                loss += self._alpha * torch.sum(torch.abs(param)) / param.data.numel()\n",
    "        return loss\n",
    "\n",
    "\n",
    "network = Net()\n",
    "torchsummary.summary(network, (3, 32, 32), device=device)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         AvgPool2d-1            [-1, 3, 16, 16]               0\n",
      "            Conv2d-2            [-1, 8, 14, 14]             224\n",
      "         MaxPool2d-3              [-1, 8, 7, 7]               0\n",
      "            Linear-4                   [-1, 10]           3,930\n",
      "================================================================\n",
      "Total params: 4,154\n",
      "Trainable params: 4,154\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-23T15:33:36.064591Z",
     "start_time": "2025-03-23T15:33:36.039138Z"
    }
   },
   "source": [
    "batch_size = 256\n",
    "batch_iterator = livenet.gen_utils.batch_iterator(train_x, train_y, batch_size)\n",
    "criterion = livenet.nets.criterion_classification_n\n",
    "optimizer = livenet.nets.create_optimizer(network)\n",
    "trainer = livenet.net_trainer.NetTrainer(network, batch_iterator, criterion, optimizer, epoch_size=len(train_x) // batch_size)\n",
    "trainer.adaptive_lr = True\n",
    "optimizer.learning_rate = 0.01\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:35:04.878376Z",
     "start_time": "2025-03-23T15:33:38.978958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#network.learning_rate = 0.0005\n",
    "trainer.step(100000)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iˈ0.000 194 2.463+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ0.405 389 2.118+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ0.912 584 2.034+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ1.651 779 1.974+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ2.416 974 1.949+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ3.232 1169 1.920+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ4.136 1364 1.906+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ4.983 1559 1.896+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ5.746 1754 1.885+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ6.491 1949 1.882+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ7.339 2144 1.868+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ8.049 2339 1.866+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ8.754 2534 1.863+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ9.458 2729 1.860+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ10.164 2924 1.857+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ11.009 3119 1.854+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ11.912 3314 1.852+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ12.507 3509 1.849+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ13.194 3704 1.852+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ13.881 3899 1.844+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ14.584 4094 1.843+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ15.301 4289 1.849+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ16.008 4484 1.839+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ16.785 4679 1.845+0.000reg params=14 lr=0.01000 <string>:34\n",
      "Iˈ17.714 4874 1.848+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ18.732 5069 1.736+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ19.324 5264 1.723+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ20.252 5459 1.724+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ21.154 5654 1.720+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ22.061 5849 1.718+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ23.254 6044 1.720+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ24.430 6239 1.717+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ25.412 6434 1.714+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ26.279 6629 1.716+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ26.858 6824 1.714+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ27.477 7019 1.714+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ28.036 7214 1.714+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ28.442 7409 1.712+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ28.988 7604 1.712+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ29.624 7799 1.712+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ30.274 7994 1.709+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ30.899 8189 1.712+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ31.536 8384 1.711+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ32.165 8579 1.710+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ32.745 8774 1.709+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ33.375 8969 1.709+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ34.005 9164 1.709+0.000reg params=14 lr=0.00500 <string>:34\n",
      "Iˈ34.664 9359 1.712+0.000reg params=14 lr=0.00250 <string>:34\n",
      "Iˈ35.426 9554 1.659+0.000reg params=14 lr=0.00250 <string>:34\n",
      "Iˈ36.180 9749 1.657+0.000reg params=14 lr=0.00250 <string>:34\n",
      "Iˈ36.926 9944 1.655+0.000reg params=14 lr=0.00250 <string>:34\n",
      "Iˈ37.674 10139 1.654+0.000reg params=14 lr=0.00250 <string>:34\n",
      "Iˈ38.432 10334 1.655+0.000reg params=14 lr=0.00250 <string>:34\n",
      "Iˈ39.195 10529 1.653+0.000reg params=14 lr=0.00250 <string>:34\n",
      "Iˈ39.947 10724 1.654+0.000reg params=14 lr=0.00250 <string>:34\n",
      "Iˈ40.777 10919 1.653+0.000reg params=14 lr=0.00250 <string>:34\n",
      "Iˈ41.582 11114 1.654+0.000reg params=14 lr=0.00250 <string>:34\n",
      "Iˈ42.407 11309 1.653+0.000reg params=14 lr=0.00250 <string>:34\n",
      "Iˈ43.219 11504 1.653+0.000reg params=14 lr=0.00250 <string>:34\n",
      "Iˈ44.036 11699 1.652+0.000reg params=14 lr=0.00250 <string>:34\n",
      "Iˈ44.792 11894 1.652+0.000reg params=14 lr=0.00250 <string>:34\n",
      "Iˈ45.326 12089 1.653+0.000reg params=14 lr=0.00125 <string>:34\n",
      "Iˈ46.011 12284 1.630+0.000reg params=14 lr=0.00125 <string>:34\n",
      "Iˈ46.818 12479 1.630+0.000reg params=14 lr=0.00125 <string>:34\n",
      "Iˈ47.393 12674 1.629+0.000reg params=14 lr=0.00125 <string>:34\n",
      "Iˈ47.948 12869 1.628+0.000reg params=14 lr=0.00125 <string>:34\n",
      "Iˈ48.853 13064 1.629+0.000reg params=14 lr=0.00125 <string>:34\n",
      "Iˈ49.652 13259 1.630+0.000reg params=14 lr=0.00063 <string>:34\n",
      "Iˈ50.485 13454 1.619+0.000reg params=14 lr=0.00063 <string>:34\n",
      "Iˈ51.401 13649 1.617+0.000reg params=14 lr=0.00063 <string>:34\n",
      "Iˈ52.260 13844 1.617+0.000reg params=14 lr=0.00063 <string>:34\n",
      "Iˈ53.136 14039 1.618+0.000reg params=14 lr=0.00063 <string>:34\n",
      "Iˈ53.886 14234 1.618+0.000reg params=14 lr=0.00063 <string>:34\n",
      "Iˈ54.377 14429 1.617+0.000reg params=14 lr=0.00063 <string>:34\n",
      "Iˈ54.884 14624 1.618+0.000reg params=14 lr=0.00063 <string>:34\n",
      "Iˈ55.524 14819 1.617+0.000reg params=14 lr=0.00063 <string>:34\n",
      "Iˈ55.970 15014 1.617+0.000reg params=14 lr=0.00063 <string>:34\n",
      "Iˈ56.407 15209 1.617+0.000reg params=14 lr=0.00031 <string>:34\n",
      "Iˈ56.900 15404 1.612+0.000reg params=14 lr=0.00031 <string>:34\n",
      "Iˈ57.271 15599 1.613+0.000reg params=14 lr=0.00031 <string>:34\n",
      "Iˈ57.673 15794 1.612+0.000reg params=14 lr=0.00031 <string>:34\n",
      "Iˈ58.100 15989 1.612+0.000reg params=14 lr=0.00031 <string>:34\n",
      "Iˈ58.845 16184 1.612+0.000reg params=14 lr=0.00031 <string>:34\n",
      "Iˈ59.435 16379 1.612+0.000reg params=14 lr=0.00031 <string>:34\n",
      "Iˈ59.994 16574 1.612+0.000reg params=14 lr=0.00016 <string>:34\n",
      "Iˈ60.524 16769 1.609+0.000reg params=14 lr=0.00016 <string>:34\n",
      "Iˈ61.411 16964 1.609+0.000reg params=14 lr=0.00016 <string>:34\n",
      "Iˈ62.282 17159 1.609+0.000reg params=14 lr=0.00016 <string>:34\n",
      "Iˈ63.039 17354 1.609+0.000reg params=14 lr=0.00016 <string>:34\n",
      "Iˈ63.754 17549 1.609+0.000reg params=14 lr=0.00016 <string>:34\n",
      "Iˈ64.365 17744 1.609+0.000reg params=14 lr=0.00016 <string>:34\n",
      "Iˈ65.041 17939 1.609+0.000reg params=14 lr=0.00016 <string>:34\n",
      "Iˈ65.702 18134 1.609+0.000reg params=14 lr=0.00016 <string>:34\n",
      "Iˈ66.083 18329 1.609+0.000reg params=14 lr=0.00016 <string>:34\n",
      "Iˈ66.738 18524 1.609+0.000reg params=14 lr=0.00016 <string>:34\n",
      "Iˈ67.627 18719 1.609+0.000reg params=14 lr=0.00008 <string>:34\n",
      "Iˈ68.399 18914 1.607+0.000reg params=14 lr=0.00008 <string>:34\n",
      "Iˈ68.961 19109 1.608+0.000reg params=14 lr=0.00008 <string>:34\n",
      "Iˈ69.353 19304 1.608+0.000reg params=14 lr=0.00008 <string>:34\n",
      "Iˈ70.081 19499 1.608+0.000reg params=14 lr=0.00008 <string>:34\n",
      "Iˈ70.830 19694 1.608+0.000reg params=14 lr=0.00004 <string>:34\n",
      "Iˈ71.584 19889 1.607+0.000reg params=14 lr=0.00004 <string>:34\n",
      "Iˈ72.444 20084 1.607+0.000reg params=14 lr=0.00004 <string>:34\n",
      "Iˈ73.317 20279 1.607+0.000reg params=14 lr=0.00004 <string>:34\n",
      "Iˈ74.179 20474 1.607+0.000reg params=14 lr=0.00004 <string>:34\n",
      "Iˈ75.044 20669 1.607+0.000reg params=14 lr=0.00004 <string>:34\n",
      "Iˈ75.935 20864 1.607+0.000reg params=14 lr=0.00002 <string>:34\n",
      "Iˈ76.893 21059 1.607+0.000reg params=14 lr=0.00002 <string>:34\n",
      "Iˈ77.736 21254 1.607+0.000reg params=14 lr=0.00002 <string>:34\n",
      "Iˈ78.482 21449 1.606+0.000reg params=14 lr=0.00002 <string>:34\n",
      "Iˈ79.243 21644 1.607+0.000reg params=14 lr=0.00002 <string>:34\n",
      "Iˈ80.123 21839 1.606+0.000reg params=14 lr=0.00002 <string>:34\n",
      "Iˈ80.995 22034 1.607+0.000reg params=14 lr=0.00002 <string>:34\n",
      "Iˈ81.894 22229 1.606+0.000reg params=14 lr=0.00002 <string>:34\n",
      "Iˈ82.763 22424 1.606+0.000reg params=14 lr=0.00002 <string>:34\n",
      "Iˈ83.637 22619 1.606+0.000reg params=14 lr=0.00002 <string>:34\n",
      "Iˈ84.460 22814 1.607+0.000reg params=14 lr=0.00002 <string>:34\n",
      "Iˈ85.187 23009 1.607+0.000reg params=14 lr=0.00001 <string>:34\n",
      "Iˈ85.187 stopped livenet/net_trainer.py:58\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-23T15:35:10.377805Z",
     "start_time": "2025-03-23T15:35:10.317289Z"
    }
   },
   "source": [
    "\n",
    "def calc_accuracy(predictions, labels):\n",
    "    _, predicted = torch.max(predictions.data, 1)\n",
    "    labels = labels.cpu().numpy()\n",
    "    labels = np.squeeze(labels, 1)\n",
    "    predicted = predicted.cpu().numpy()\n",
    "    correct = np.sum(predicted == labels)\n",
    "    total = len(labels)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "def get_loss(trainer, x, y):\n",
    "    with torch.no_grad():\n",
    "        pred = trainer.network(x)\n",
    "        loss = trainer.criterion(pred, y)\n",
    "        loss = loss.cpu().item()\n",
    "        return loss\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_outputs = network(train_x)\n",
    "    test_outputs = network(test_x)\n",
    "\n",
    "train_loss = get_loss(trainer, train_x, train_y)\n",
    "test_loss = get_loss(trainer, test_x, test_y)\n",
    "LOG(f\"loss: train: {train_loss:.3f} test: {test_loss:.3f}\")\n",
    "\n",
    "train_accuracy = calc_accuracy(train_outputs, train_y)\n",
    "test_accuracy = calc_accuracy(test_outputs, test_y)\n",
    "LOG(f\"accuracy, train: {100 * train_accuracy:.1f}% test: {100 * test_accuracy:.1f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iˈ0.000 loss: train: 1.606 test: 1.721 \n",
      "Iˈ0.006 accuracy, train: 61.7% test: 58.7% \n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-23T15:27:53.294358Z",
     "start_time": "2025-03-23T15:27:53.245933Z"
    }
   },
   "source": [
    "def test_func():\n",
    "    return livenet.gen_utils.batch_iterator(*test_whole_data, batch_size=256, only_one_epoch=True)\n",
    "\n",
    "def train_func():\n",
    "    return livenet.gen_utils.batch_iterator(*train_whole_data, batch_size=256, only_one_epoch=True)\n",
    "import time\n",
    "\n",
    "net._alpha = 0.0001\n",
    "\n",
    "def criterion(input, target):\n",
    "    return nn.functional.cross_entropy(input, target) / math.log(2)\n",
    "\n",
    "# optimizer = lib.optimizer.MyOptimizer(net.parameters(), lr=0.01)\n",
    "t0 = time.time()\n",
    "for epoch in range(50):\n",
    "    print(f\"{time.time() - t0:.3f} sec\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_func(), 1):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss += net.reg_loss_func()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        n_observe = 4 * 195\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print(f'[{epoch + 1}, {i:5d}] running loss: {running_loss / i:.2f}')\n",
    "    running_loss = 0.0\n",
    "    calc_stats(net, train_whole_data)\n",
    "    calc_stats(net, test_whole_data)\n",
    "    #lr schedule\n",
    "    if True:\n",
    "        observed = np.array(losses[-n_observe:])\n",
    "        av1 = np.average(observed[:len(observed) // 2])\n",
    "        av2 = np.average(observed[len(observed) // 2:])\n",
    "        print(f\"av1={av1:.4f} av2={av2:.4f}\")\n",
    "        slope, pvalue = livenet.stat_utils.get_slope_and_pvalue(losses[-n_observe:])\n",
    "        print(f\"slope={slope:.1e} pvalue={pvalue:.1e} lr={optimizer.param_groups[0]['lr']}\")\n",
    "        if slope >= 0.0:\n",
    "            optimizer.param_groups[0][\"lr\"] /= 1.4\n",
    "            print(f\"reduced lr to {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "print('Finished Training')\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      5\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m livenet.gen_utils.batch_iterator(*train_whole_data, batch_size=\u001B[32m256\u001B[39m, only_one_epoch=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtime\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[43mnet\u001B[49m._alpha = \u001B[32m0.0001\u001B[39m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcriterion\u001B[39m(\u001B[38;5;28minput\u001B[39m, target):\n\u001B[32m     11\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m nn.functional.cross_entropy(\u001B[38;5;28minput\u001B[39m, target) / math.log(\u001B[32m2\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'net' is not defined"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
